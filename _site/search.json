[
  {
    "objectID": "ECD.html#the-interplay-of-design-and-statistical-modeling",
    "href": "ECD.html#the-interplay-of-design-and-statistical-modeling",
    "title": "ECD Intro",
    "section": "The Interplay of Design and Statistical Modeling",
    "text": "The Interplay of Design and Statistical Modeling\nStatistical models must be selected/tailored according to the needs of the assessment\nSuch selection and adaptation is only meaningful in the larger context of the assessment design\nUnderstanding the discipline of assessment design is a necessary prerequisite for statistical modeling\nEvidence Centered Design is an assessment design framework with general applicability and utility"
  },
  {
    "objectID": "ECD.html#test-design-considerations",
    "href": "ECD.html#test-design-considerations",
    "title": "ECD Intro",
    "section": "Test Design Considerations",
    "text": "Test Design Considerations\n\nStakeholders\nRequirements\n\nPurpose of the test\nIntended population\n\nProspective Score Report\nEvidence-Centered Design\n\nClaims\nValidity\n\nSpecifications"
  },
  {
    "objectID": "ECD.html#evidence-centered-designadvantages",
    "href": "ECD.html#evidence-centered-designadvantages",
    "title": "ECD Intro",
    "section": "Evidence-Centered Design—Advantages",
    "text": "Evidence-Centered Design—Advantages\n\nEvidence Centered Design (ECD) provides a mechanism for\n\nCapturing and documenting information about the structure and strength of evidentiary relationships.\nCoordinating the work of test developers in authoring tasks and psychometricians in calibrating the measurement model.\nDocumenting the scientific information that provides the foundation for the assessment and its validity."
  },
  {
    "objectID": "ECD.html#evidence-centered-designcentral-question",
    "href": "ECD.html#evidence-centered-designcentral-question",
    "title": "ECD Intro",
    "section": "Evidence-Centered Design–Central Question",
    "text": "Evidence-Centered Design–Central Question\n\nEvidence-centered design centers around the questions:\n\n“What can we observe about an examinee’s performance which will provide evidence that the examinee has or does not have the knowledge, skills and abilities we wish to make claims about?”\n\n\n“How can we structure situations to be able to make those observations?”\n\n\nThis process results in the Conceptual Assessment Framework (CAF)"
  },
  {
    "objectID": "ECD.html#the-initial-frame",
    "href": "ECD.html#the-initial-frame",
    "title": "ECD Intro",
    "section": "The Initial Frame",
    "text": "The Initial Frame\n\nWhy are we measuring?\n\nWhat are the goals and the desires for use of this assessment?\nProspective Score Report\n\nWho are we measuring?\n\nWho would take the assessment?\nWho would view results and for what purpose?\n\nGoals of the assessment that represent the targets around which the rest of the design process is oriented"
  },
  {
    "objectID": "ECD.html#activity-1-cont",
    "href": "ECD.html#activity-1-cont",
    "title": "ECD Intro",
    "section": "Activity 1 (cont)",
    "text": "Activity 1 (cont)\nList a bunch of activities that you may want prospective drivers to do in their exam\nWhat is environment of the task\nWhat are manipulable features of the task?\nPick one of the tasks you created and build an evidence model for it.\nWhat are some observable outcomes? their possible values?\nWhich proficiencies do they measure?\nThink a bit about putting this driver’s test together\nHow many tasks do we need of what types?\nHow much time will be spent in written tests? On the road? In simulators?\nHow do we verify the identity of applicants?"
  },
  {
    "objectID": "ECD.html#cup-and-cap-notation",
    "href": "ECD.html#cup-and-cap-notation",
    "title": "ECD Intro",
    "section": "Cup and Cap notation",
    "text": "Cup and Cap notation\nIn probability theory, events are sets (sets of balls in the urn).\nLet \\(A\\) and \\(B\\) be two events\n\nUnion: Either \\(A\\) or \\(B\\) occurs \\[ A \\cup B \\qquad A \\vee B \\]\nIntersection: Both \\(A\\) and \\(B\\) occur \\[ A \\cap B \\qquad A \\wedge B \\]\n\nSometimes also just \\(\\Pr(A,B)\\)\n\nComplement: Not \\(A\\) \\[ \\neg A \\qquad \\overline{A} \\]\n\n\\(\\Pr(\\overline{A}) = 1- \\Pr(A)\\)$"
  },
  {
    "objectID": "ECD.html#law-of-total-probability",
    "href": "ECD.html#law-of-total-probability",
    "title": "ECD Intro",
    "section": "Law of Total Probability",
    "text": "Law of Total Probability\n\\[ \\Pr(E) = \\Pr(E|H) \\Pr(H) + \\Pr(E|\\overline{H})\\Pr(\\overline{H}) \\]\n\\[ \\Pr(B) = \\sum_i \\Pr(B|A_i)\\Pr(A_i) \\]\nWhere $ A_i A_j =$ and \\(\\bigcup_i A_i = \\Omega\\)"
  },
  {
    "objectID": "ECD.html#independence",
    "href": "ECD.html#independence",
    "title": "ECD Intro",
    "section": "Independence",
    "text": "Independence\n\n\n\n\n\n\\[ \\Pr(B) = \\Pr(B|A) = \\Pr(B|\\overline{A}) \\] \\[ \\Pr(A) = \\Pr(A|B) = \\Pr(A|\\overline{B}) \\] \\[ \\Pr(A \\cap B) = \\Pr(A|B)\\Pr(B) = \\Pr(A)\\Pr(B) \\]\n\nKnowing \\(A\\) provides no information about \\(B\\) and vise versa."
  },
  {
    "objectID": "ECD.html#accident-proneness-feller-1968",
    "href": "ECD.html#accident-proneness-feller-1968",
    "title": "ECD Intro",
    "section": "Accident Proneness (Feller, 1968)",
    "text": "Accident Proneness (Feller, 1968)\n\nDriving Skill: 5/6 Normal, 1/6 Accident Prone\nProbability of an accident in a given year\n\n1/100 for Normal drivers\n1/10 for Accident prone drivers\n\nAccidents happen independently in each year\nWhat is the probability a randomly chosen driver will have an accident in Year 1?\nGiven a driver had an accident in Year 1, what is probability of accident in Year 2?"
  },
  {
    "objectID": "ECD.html#accident-proneness-year-1",
    "href": "ECD.html#accident-proneness-year-1",
    "title": "ECD Intro",
    "section": "Accident Proneness (Year 1)",
    "text": "Accident Proneness (Year 1)\nWhat is the probability a randomly chosen driver will have an accident in Year 1? Year 2?\n\\(\\Pr(Y_i)\\). – Prob of accident in a given year.\n\\[ \\Pr(A_i) = \\Pr(A_i|N)\\Pr(N) +\n\\Pr(A_i|\\overline{N})\\Pr(\\overline{N}) \\]\n\nDrivingSkill <- c(N=5/6,A=1/6)\nAccLike <- cbind(Yes=c(N=1/100,A=1/10),No=c(N=99/100,A=9/10))\nYear1 <- sweep(AccLike,1,DrivingSkill,\"*\")\nYear1\n\n          Yes    No\nN 0.008333333 0.825\nA 0.016666667 0.150\n\nsum(Year1[,\"Yes\"])\n\n[1] 0.025"
  },
  {
    "objectID": "ECD.html#accident-proneness-year-ii",
    "href": "ECD.html#accident-proneness-year-ii",
    "title": "ECD Intro",
    "section": "Accident Proneness (Year II)",
    "text": "Accident Proneness (Year II)\nGiven a driver had an accident in Year 1, what is probability of accident in Year 2?\n\\[ \\begin{array}{rcl}\n\\Pr(A_1 \\cap A_2) &=& \\Pr(A_1 \\cap A_2|N)\\Pr(N) + \\Pr(A_1 \\cap\nA_2|\\overline{N}) \\Pr(\\overline{N}) \\\\\n  &=& \\Pr(A_1|N)\\Pr(A_2|N)\\Pr(N) + \\Pr(A_1|\\overline{N})\n\\Pr(A_2|\\overline{N}) \\Pr(\\overline{N})\n   \\end{array} \\]\n\nAcc2Like <- AccLike\nAcc2Like[,\"Yes\"] <- AccLike[,\"Yes\"]^2\nAcc2Like[,\"No\"] <- 1 -Acc2Like[,\"Yes\"]\nYear12 <- sweep(Acc2Like,1,DrivingSkill,\"*\")\nYear12\n\n           Yes      No\nN 8.333333e-05 0.83325\nA 1.666667e-03 0.16500\n\nsum(Year12[,\"Yes\"])\n\n[1] 0.00175"
  },
  {
    "objectID": "ECD.html#accident-prone-chain",
    "href": "ECD.html#accident-prone-chain",
    "title": "ECD Intro",
    "section": "Accident Prone (Chain)",
    "text": "Accident Prone (Chain)\n\\(\\Pr(Y_2 | Y_1)\\) – Accident in 2nd year given accident in first year.\n\nsum(Year12[,\"Yes\"])/sum(Year1[,\"Yes\"])\n\n[1] 0.07"
  },
  {
    "objectID": "ECD.html#explanation",
    "href": "ECD.html#explanation",
    "title": "ECD Intro",
    "section": "Explanation",
    "text": "Explanation\n\\(\\Pr(S=\\text{normal}|A_i)\\) – Probability in normal category given accident.\n\nDiagrammeR::grViz(\"\ndigraph AP {\n  Driving -> Year1;\n  Driving -> Year2;\n}\")"
  },
  {
    "objectID": "ECD.html#conditional-independence",
    "href": "ECD.html#conditional-independence",
    "title": "ECD Intro",
    "section": "Conditional Independence",
    "text": "Conditional Independence\n\nConditional Independence: $(Y_1,Y_2|S) = (Y_1|S) (Y_2|S) $\nYears are marginally dependent.\nSeparation in graph tells the story.\nInformation flows from from Year1 to Driving Skill to Year2"
  },
  {
    "objectID": "ECD.html#another-example",
    "href": "ECD.html#another-example",
    "title": "ECD Intro",
    "section": "Another Example",
    "text": "Another Example\n\nDiagrammeR::grViz(\"\ndigraph Autotrain {\n  Train -> COVID;\n  Train -> MaskOnTrain;\n  MaskOnTrain -> COVID;\n  Vaccine -> COVID;\n  COVID -> fever;\n  COVID -> congestion;\n  COVID -> pcrTest;\n}\")"
  },
  {
    "objectID": "ECD.html#competing-explanations",
    "href": "ECD.html#competing-explanations",
    "title": "ECD Intro",
    "section": "Competing Explanations",
    "text": "Competing Explanations\n\nDiagrammeR::grViz(\"\ndigraph CompExpl {\n  Skill1 -> X\n  Skill2 -> X\n}\")\n\n\n\n\n\n\nSkill1 and Skill2 are (a priori) independent in population\nTask X requires both skills (conjunctive model)\nAnswer the following questions:\n\nWhat is posterior of Skill2 after learning X=False, and Skill1=High?\nWhat is posterior of Skill1 after learning X=False, and Skill2=High?\nWhat is true of joint posterior of Skill1 and Skill2 after learning X=False?"
  },
  {
    "objectID": "ECD.html#d-separation-example",
    "href": "ECD.html#d-separation-example",
    "title": "ECD Intro",
    "section": "D-separation Example",
    "text": "D-separation Example\n\nDiagrammeR::grViz('\ndigraph DSep {\n  rankdir = \"LR\";\n  A -> B; A -> C;\n  B -> D; C -> D;\n  D -> E -> F;\n}')\n\n\n\n\n\n\\(B\\) and \\(C\\) are independent if \\(A\\) is known and all of \\(D\\), \\(E\\) or \\(F\\) are not known.\n\\(D\\) is independent of \\(F\\) if \\(E\\) is known."
  },
  {
    "objectID": "ECD.html#d-separation-exercise",
    "href": "ECD.html#d-separation-exercise",
    "title": "ECD Intro",
    "section": "D-Separation Exercise",
    "text": "D-Separation Exercise\n\nDiagrammeR::grViz('\ndigraph DSepEx {\n  rankdir = \"TB\";\n  A -> D; B -> D; B -> E; C -> E;\n  D -> F; D -> G; E -> G; E -> H;\n}')\n\n\n\n\n\n\nAre A and C independent if\n\nWe have observed no other variables?\n\nWhat could we condition on to make A and C independent?\n\nWe have observed F and H?\n\nWhat else could we condition on to make A and C independent?\n\nWe have observed G ?\n\nWhat else could we condition on to make A and C independent?"
  },
  {
    "objectID": "ECD.html#building-up-complex-networks-irt",
    "href": "ECD.html#building-up-complex-networks-irt",
    "title": "ECD Intro",
    "section": "Building Up Complex Networks: IRT",
    "text": "Building Up Complex Networks: IRT\n\nDiagrammeR::grViz('\ndigraph IRT {\n  subgraph{ Q[label=\"θ\"] }\n  subgraph {\n  X1; X2; andC[shape=none,label=\"...\"]; XJ\n  }\n  Q -> X1; Q-> X2; Q->andC [style=\"invis\"]; Q->XJ\n}')\n\n\n\n\n\nFor example, in IRT, item responses are conditionally independent given \\(\\theta\\):\n\\[ p(X_1,\\ldots,X_J,\\theta) = p(\\theta) \\prod_{j=1}^{J} p(X_j|\\theta)\\]"
  },
  {
    "objectID": "ECD.html#bayes-net",
    "href": "ECD.html#bayes-net",
    "title": "ECD Intro",
    "section": "Bayes net",
    "text": "Bayes net\n\nDiagrammeR::grViz(\"\ndigraph ABN {\n  A -> C; B -> C;\n  C -> D; C -> E;\n  D -> F; E -> F\n}\")\n\n\n\n\n\nOne factor for each node in graph\nThis factor is conditioned on parents in graph\n“Prior” nodes have no parents\n\\[p(A)p(B)p(C|A\\,B)p(D|C)p(E|C)p(F|D\\,E) = p(A\\,B\\,C\\,D\\,E\\,F)\\]\nDigraph must be acyclic"
  },
  {
    "objectID": "ECD.html#activity-2-build-a-bayes-net",
    "href": "ECD.html#activity-2-build-a-bayes-net",
    "title": "ECD Intro",
    "section": "Activity 2: Build a Bayes Net",
    "text": "Activity 2: Build a Bayes Net\nPick one of the tasks you created and build an a Bayes net in Netica:\nProficiency variables, their possible values\nObservable variables, their possible values\nConditional probabilities between Proficiency variables and Observable variables\nAdd your observables to the proficiency model you made in Netica"
  },
  {
    "objectID": "Scoring.html",
    "href": "Scoring.html",
    "title": "Scoring Individual Students",
    "section": "",
    "text": "The RNetica suite consists of a number of packages:\n\n\n\nRNetica Package Suite\n\n\n\nCPTtools is a collection of tools for building conditional probability tables (particularly, the DiBello models). It stands alone.\nRNetica links R to the Netica Bayes net engine. Note: non-trivial uses of RNetica require a Netica API (not GUI) license from Norsys.\n\n\n\n\nThe Peanut object oriented framework rests on top of CPTtools and RNetica.\n\n\n\nRNetica Package Suite\n\n\n\nCPTtools is a collection of tools for building conditional probability tables (particularly, the DiBello models). It stands alone.\nRNetica links R to the Netica Bayes net engine. _Note: non-trivial uses of RNetica require a Netica API (not GUI) license from Norsys.\n\n\n\n\nThe Peanut object oriented framework rests on top of CPTtools and RNetica.\n\n\n\nRNetica Package Suite\n\n\n\nPeanut (a corrupt reading of Pnet, or parameterized network) is an object oriented frame work on top of CPTtools.\nPNetica is an implementation of the Peanut framework using RNetica.\n\nPackages can be installed through R-Universe\n\ninstall.packages(c('CPTtootls','RNetica','Peanut','PNetica'),\n                 repos = c('https://ralmond.r-universe.dev', 'https://cloud.r-project.org'))\n\nSource code is on github https://github.com/ralmond/.\n\n\n\n\nR – GPL-3 (Free and open source)\nRNetica – Artistic (Free and open source)\nNetica.dll/libNetica.so– Commercial (open API, but not open source)\n\nFree Student/Demo version\n\nLimited number of nodes\nLimited usage (education, evaluation of Netica)\n\nPaid version (seehttp://www.norsys.com/for price information)\n\nNeed to purchase API not GUI version ofNetica\nMay want both (use GUI to visualize networks built in RNetica)\n\n\nCPTtools, Peanut – Artistic (Free and open source), does not depend on Netica\nRNetica – Artistic, but depends on RNetica.\n\n\n\n\n\nWhen you purchase a license, Norsys will send you a license key. Something that looks like:\n“+User/Organization/120,310-details/XXXXX”\n(Where I’ve obscured the last 5 security digits) 120 – GUI, 310 – API (I think)\n\nThree ways of installing the license key:\n\nUse as argument to NeticaSession(...,LicenseKey=XXX)\nSet options(NeticaLicenseKey=XXX)\n\n\nThis can be set in .Rprofile in your home directory.\n\n\nSet an environmental variable NeticaLicenseKey before launching R.\n\n\nThis can be set in .Renviron in your home directory.\n\n\n\n\nAfter you load RNetica you need to start the session. This is when you pass the license key.\n\nlibrary(RNetica)\nsess <- NeticaSession(LicenseKey=NeticaLicenseKey)\nstartSession(sess)\n\n\nlibrary(RNetica)\n\nLoading required package: CPTtools\n\n\nLoading required package: futile.logger\n\nsess <- NeticaSession(LicenseKey=\"\")\nstartSession(sess)\n\nNetica 5.04 Linux (AF), (C) 1992-2012 Norsys Software Corp.\n\nNetica operating without a password; there are some limitations.\n\n\nEverything in this tutorial should run without the license.\n\n\n\n\nWhen starting/restarting Netica\nWhen creating a network, or reading one from a file.\nWhen searching for networks.\nCertain global properties\n\nNeticaBN objects have a $session proprty which points back to the session.\nNeticaNode objects have a $node property which points back to the network (which points to the session).\n\n\n\nR and Netica have two different workspaces (memory heaps)\nR workspace is saved and restored automatically when you quick and restart R.\nNeticaheap must be reconnected manually.\n\n\n\nR and Netica Heaps\n\n\n\n\n\nWhen RNetica creates/finds aNeticaobject it creates a corresponding R object\nIf the R object is active then it points to the Netica object, and the Netica object points back at it.\nIf the pointer gets broken (saving and restarting R, deleting the network/node then the R object becomes inactive.\nThe function is.active(nodeOrNet) test to see if the node/net is active.\n\n\n\nR and Netica Heap"
  },
  {
    "objectID": "Scoring.html#mini-aced-proficiency-model",
    "href": "Scoring.html#mini-aced-proficiency-model",
    "title": "Scoring Individual Students",
    "section": "Mini-ACED Proficiency model",
    "text": "Mini-ACED Proficiency model\nSubset of ACED network: Shute, Hansen & Almond (2008); http://ecd.ralmond.net/ecdwiki/ACED\nDownload the mini-ACED file Unzip it in miniACED and that this folder is in the same directory as this qmd file.\nNext, change directory into the directory that contains miniACED\n\nif (\"miniACED-Geometric.csv\" %in% list.files(\"miniACED\")) {\n  print(\"You're good to go.\")\n} else {\n  stop(\"You need to unpack 'miniACED.zip' or go to the directory where it is.\")\n}\n\n[1] \"You're good to go.\"\n\n\n\n\n\nProficiency Model"
  },
  {
    "objectID": "Scoring.html#mini-aced-em-fragments",
    "href": "Scoring.html#mini-aced-em-fragments",
    "title": "Scoring Individual Students",
    "section": "Mini-ACED EM Fragments",
    "text": "Mini-ACED EM Fragments\nAll ACED tasks were scored correct/incorrect\nEach evidence model is represented by a fragment consisting of observables with stub edges indicating where it should be adjoined with the network.\n\n\n\nCommon Ratio Easy\n\n\n\n\n\nModel Table Extend Hard"
  },
  {
    "objectID": "Scoring.html#preliminaries",
    "href": "Scoring.html#preliminaries",
    "title": "Scoring Individual Students",
    "section": "Preliminaries",
    "text": "Preliminaries"
  },
  {
    "objectID": "Scoring.html#task-to-em-map",
    "href": "Scoring.html#task-to-em-map",
    "title": "Scoring Individual Students",
    "section": "Task to EM map",
    "text": "Task to EM map\nNeed a table to tell us which EM to use with which task\n\n## Read in task->evidence model mapping\nEMtable <- read.csv(file.path(\"miniACED\",\"MiniACEDEMTable.csv\"),\n                    row.names=1,\n                    as.is=2) #Keep EM names as strings\nEMtable\n\n                                                 EM    X   Y\ntCommonRatio1a                    CommonRatioEasyEM  108 294\ntCommonRatio1b                    CommonRatioEasyEM  108 414\ntCommonRatio2a                     CommonRatioMedEM  108 534\ntCommonRatio2b                     CommonRatioMedEM  108 654\ntCommonRatio3a                    CommonRatioHardEM  108 774\ntCommonRatio3b                    CommonRatioHardEM  108 894\ntExamplesGeometric1a                 ExamplesEasyEM  342 294\ntExamplesGeometric1b                 ExamplesEasyEM  342 414\ntExamplesGeometric2a                  ExamplesMedEM  342 534\ntExamplesGeometric2b                  ExamplesMedEM  342 654\ntExamplesGeometric3a                 ExamplesHardEM  342 774\ntExamplesGeometric3b                 ExamplesHardEM  342 894\ntExtendGeometric1a                     ExtendEasyEM  588 294\ntExtendGeometric1b                     ExtendEasyEM  588 414\ntExtendGeometric2a                      ExtendMedEM  588 534\ntExtendGeometric2b                      ExtendMedEM  588 654\ntExtendGeometric3a                     ExtendHardEM  588 774\ntExtendGeometric3b                     ExtendHardEM  588 894\ntTableExtendGeometric1a           TableExtendEasyEM 1134 282\ntTableExtendGeometric1b           TableExtendEasyEM 1134 402\ntTableExtendGeometric2a            TableExtendMedEM 1134 522\ntTableExtendGeometric2b            TableExtendMedEM 1134 642\ntTableExtendGeometric3a           TableExtendHardEM 1134 762\ntTableExtendGeometric3b           TableExtendHardEM 1134 882\ntModelExtendTableGeometric1a ModelTableExtendEasyEM  858 288\ntModelExtendTableGeometric1b ModelTableExtendEasyEM  858 408\ntModelExtendTableGeometric2a  ModelTableExtendMedEM  858 528\ntModelExtendTableGeometric2b  ModelTableExtendMedEM  858 648\ntModelExtendTableGeometric3a ModelTableExtendHardEM  858 768\ntModelExtendTableGeometric3b ModelTableExtendHardEM  858 888\n\n\n\n## Scoring Script\n## Preliminaries\n#| eval=FALSE\nlibrary(RNetica)\nsess <- NeticaSession()\nstartSession(sess)\n\nNetica environment already initialized"
  },
  {
    "objectID": "Scoring.html#read-in-the-network.",
    "href": "Scoring.html#read-in-the-network.",
    "title": "Scoring Individual Students",
    "section": "Read in the Network.",
    "text": "Read in the Network.\n\n## Read in network -- Do this every time R is restarted\nprofModel <- ReadNetworks(file.path(\"miniACED\",\"miniACEDPnet.dne\"),session = sess)\n## If profModels already exists could also use\n\n## Reconnect nodes -- Do this every time R is restarted\nallNodes <- NetworkAllNodes(profModel)\nsgp <- allNodes$SolveGeometricProblems\nsgp\n\nDiscrete  Netica Node named  SolveGeometricProblems in network  MiniACEDPM \n  Node is currently active.\nStates are:  High, Medium, Low"
  },
  {
    "objectID": "Scoring.html#aside-1-node-sets",
    "href": "Scoring.html#aside-1-node-sets",
    "title": "Scoring Individual Students",
    "section": "Aside 1 – Node Sets",
    "text": "Aside 1 – Node Sets\nNode sets can be viewed as either\nA. a set of labels assigned to each node.\nB. a set of nodes which have a particular label.\nIn RNetica, these are very useful as they define collections of nodes that might be interesting in some way (e.g., Proficiency variables, Observable variable, background variables)\nNode set operations yeild a list of nodes; iterating over that set is often very useful."
  },
  {
    "objectID": "Scoring.html#node-set-examples",
    "href": "Scoring.html#node-set-examples",
    "title": "Scoring Individual Students",
    "section": "Node Set Examples",
    "text": "Node Set Examples\n\n## Node Sets\nNetworkNodeSets(profModel)\n\n[1] \"pnodes\"        \"Proficiencies\"\n\nNetworkNodesInSet(profModel,\"pnodes\")\n\n$TableGeometric\nDiscrete  Netica Node named  TableGeometric in network  MiniACEDPM \n  Node is currently active.\nStates are:  High, Medium, Low \n\n$ModelGeometric\nDiscrete  Netica Node named  ModelGeometric in network  MiniACEDPM \n  Node is currently active.\nStates are:  High, Medium, Low \n\n$ExtendGeometric\nDiscrete  Netica Node named  ExtendGeometric in network  MiniACEDPM \n  Node is currently active.\nStates are:  High, Medium, Low \n\n$ExamplesGeometric\nDiscrete  Netica Node named  ExamplesGeometric in network  MiniACEDPM \n  Node is currently active.\nStates are:  High, Medium, Low \n\n$CommonRatio\nDiscrete  Netica Node named  CommonRatio in network  MiniACEDPM \n  Node is currently active.\nStates are:  High, Medium, Low \n\n$SolveGeometricProblems\nDiscrete  Netica Node named  SolveGeometricProblems in network  MiniACEDPM \n  Node is currently active.\nStates are:  High, Medium, Low"
  },
  {
    "objectID": "Scoring.html#more-node-set-examples",
    "href": "Scoring.html#more-node-set-examples",
    "title": "Scoring Individual Students",
    "section": "More Node Set Examples",
    "text": "More Node Set Examples\n\nprofNodes <- NetworkNodesInSet(profModel,\"Proficiencies\")\nNodeSets(sgp)\n\n[1] \"pnodes\"        \"Proficiencies\"\n\n\nAdding a node to a set.\n\n## These are all settable\nNodeSets(sgp) <- c(NodeSets(sgp),\"HighLevel\")\nNodeSets(sgp)\n\n[1] \"HighLevel\"     \"pnodes\"        \"Proficiencies\""
  },
  {
    "objectID": "Scoring.html#aside-2-common-net-operations",
    "href": "Scoring.html#aside-2-common-net-operations",
    "title": "Scoring Individual Students",
    "section": "Aside 2: Common Net operations",
    "text": "Aside 2: Common Net operations\nJust about everything that can be done through the Netica GUI, can be done through the Netica API, and hence through R Netica. [In practice, the API version has lagged the GUI version, and my RNetica release lag Norsys’s API updates.] Many more examples are in the RNetica help.\n\n## Querying Nodes\nNodeStates(sgp)   #List states\n\n    High   Medium      Low \n  \"High\" \"Medium\"    \"Low\" \n\nNodeParents(sgp)  #List parents\n\nnamed list()"
  },
  {
    "objectID": "Scoring.html#more-rnetica-queries",
    "href": "Scoring.html#more-rnetica-queries",
    "title": "Scoring Individual Students",
    "section": "More RNetica Queries",
    "text": "More RNetica Queries\n\nNodeLevels(sgp)   #List numeric values associated with states\n\n      High     Medium        Low \n 0.9674216  0.0000000 -0.9674216 \n\nNodeProbs(sgp) # Conditional Probability Table (as array)\n\nSolveGeometricProblems\n  High Medium    Low \n0.1532 0.2784 0.5684 \nattr(,\"class\")\n[1] \"CPA\"   \"array\"\n\n## These are all settable (can be used on RHS of <-) for model\n## construction"
  },
  {
    "objectID": "Scoring.html#conditional-probability-tables-as-data-frame",
    "href": "Scoring.html#conditional-probability-tables-as-data-frame",
    "title": "Scoring Individual Students",
    "section": "Conditional Probability Tables (as Data Frame)",
    "text": "Conditional Probability Tables (as Data Frame)\n\nsgp[] # Conditional Probability Table (as data frame)\n\n  SolveGeometricProblems.High SolveGeometricProblems.Medium \n                       0.1532                        0.2784 \n   SolveGeometricProblems.Low \n                       0.5684 \n\n\nCan use [] operator to select rows or elements\nCan set table or (row or cell).\nCPTtools package has tools for building tables.\n\nhelp(package=\"CPTtools\")"
  },
  {
    "objectID": "Scoring.html#inference",
    "href": "Scoring.html#inference",
    "title": "Scoring Individual Students",
    "section": "Inference",
    "text": "Inference\nNetworks must be compiled before they are used for inference.\n\n## Inference\nCompileNetwork(profModel) #Lightning bolt on GUI \n## Must do this before inference\n## Recompiling an already compiled network is harmless\n\n\n## Enter Evidence by setting values for these functions\nNodeValue(sgp) #View or set the value\n\n[1] NA\n\nNodeLikelihood(sgp) #Virtual evidence\n\n  High Medium    Low \n     1      1      1"
  },
  {
    "objectID": "Scoring.html#beliefs-marginal-probabilities",
    "href": "Scoring.html#beliefs-marginal-probabilities",
    "title": "Scoring Individual Students",
    "section": "Beliefs (Marginal Probabilities)",
    "text": "Beliefs (Marginal Probabilities)\n\n## Query beliefs\nNodeBeliefs(sgp) #Current probability (given entered evidence)\n\n  High Medium    Low \n0.1532 0.2784 0.5684 \n\nNodeExpectedValue(sgp) #If node has values, EAP\n\n[1] -0.4016734\nattr(,\"std_dev\")\n[1] 0.7169429\n\n## These aren't settable\n\n\n## Retract Evidence\nRetractNodeFinding(profNodes$ExamplesGeometric)\nRetractNetFindings(profModel)"
  },
  {
    "objectID": "Scoring.html#example-enter-evidence",
    "href": "Scoring.html#example-enter-evidence",
    "title": "Scoring Individual Students",
    "section": "Example: Enter Evidence",
    "text": "Example: Enter Evidence\n\n## Enter Evidence\nNodeFinding(profNodes$CommonRatio) <- \"Medium\"\n## Enter Evidence \"Not Low\" (\"High or Medium\")\nNodeLikelihood(profNodes$ExamplesGeometric) <- c(1,1,0)\n\nNodeBeliefs(sgp) #Current probability (given entered evidence)\n\n     High    Medium       Low \n0.0000000 0.1811515 0.8188485 \n\nNodeExpectedValue(sgp) #If node has values, EAP\n\n[1] -0.7921717\nattr(,\"std_dev\")\n[1] 0.3725963"
  },
  {
    "objectID": "Scoring.html#example-retract-evidence",
    "href": "Scoring.html#example-retract-evidence",
    "title": "Scoring Individual Students",
    "section": "Example: Retract Evidence",
    "text": "Example: Retract Evidence\n\n## Retract Evidence\nRetractNetFindings(profModel)\n\nMany more examples:\n\nhelp(RNetica)"
  },
  {
    "objectID": "Scoring.html#back-to-work",
    "href": "Scoring.html#back-to-work",
    "title": "Scoring Individual Students",
    "section": "Back to work",
    "text": "Back to work\nSimple Scoring Example\nStart New Student Copy the proficiency model to make student model.\n\nFred.SM <- CopyNetworks(profModel,\"Fred\")\nFred.SMvars <- NetworkAllNodes(Fred.SM)\nCompileNetwork(Fred.SM)"
  },
  {
    "objectID": "Scoring.html#setup-score-history.",
    "href": "Scoring.html#setup-score-history.",
    "title": "Scoring Individual Students",
    "section": "Setup score history.",
    "text": "Setup score history.\n\nprior <- NodeBeliefs(Fred.SMvars$SolveGeometricProblems)\nFred.History <- matrix(prior,1,3)\nrow.names(Fred.History) <- \"*Baseline*\"\ncolnames(Fred.History) <- names(prior)\nFred.History\n\n             High Medium    Low\n*Baseline* 0.1532 0.2784 0.5684"
  },
  {
    "objectID": "Scoring.html#fred-does-a-task",
    "href": "Scoring.html#fred-does-a-task",
    "title": "Scoring Individual Students",
    "section": "Fred does a task",
    "text": "Fred does a task\nTask name and data.\n\nt.name <- \"tCommonRatio1a\"\nt.isCorrect <- \"Yes\"\n\nAdjoin SM and EM\n\nEMnet <- ReadNetworks(file.path(\"miniACED\",\n                                paste(EMtable[t.name,\"EM\"],\"dne\",sep=\".\")),\n                      session = sess)\nobs <- AdjoinNetwork(Fred.SM,EMnet)\nnames(NetworkAllNodes(Fred.SM)) \n\n[1] \"SolveGeometricProblems\" \"CommonRatio\"            \"ExamplesGeometric\"     \n[4] \"ExtendGeometric\"        \"ModelGeometric\"         \"TableGeometric\"        \n[7] \"isCorrect\"             \n\n## Fred.SM is now the Motif for the current task.\nCompileNetwork(Fred.SM)"
  },
  {
    "objectID": "Scoring.html#absorb-evidence",
    "href": "Scoring.html#absorb-evidence",
    "title": "Scoring Individual Students",
    "section": "Absorb Evidence",
    "text": "Absorb Evidence\nEnter finding\n\nNodeFinding(obs$isCorrect) <- t.isCorrect\n\nCalculate statistics of interest\n\npost <- NodeBeliefs(Fred.SMvars$SolveGeometricProblems)\nFred.History <- rbind(Fred.History,new=post)\nrownames(Fred.History)[nrow(Fred.History)] <- paste(t.name,t.isCorrect,sep=\"=\")\nFred.History\n\n                       High    Medium       Low\n*Baseline*         0.153200 0.2784000 0.5684000\ntCommonRatio1a=Yes 0.160016 0.2893454 0.5506387"
  },
  {
    "objectID": "Scoring.html#cleanup",
    "href": "Scoring.html#cleanup",
    "title": "Scoring Individual Students",
    "section": "Cleanup",
    "text": "Cleanup\nNetwork and Observable no longer needed, so absorb it:\n\nDeleteNetwork(EMnet) ## Delete EM\n#try(AbsorbNodes(obs))\n## Currently, there is a Netica bug with Absorb Nodes, we will\n## leave this node in place, as that is mostly harmless."
  },
  {
    "objectID": "Scoring.html#nd-task",
    "href": "Scoring.html#nd-task",
    "title": "Scoring Individual Students",
    "section": "2nd Task",
    "text": "2nd Task\nWrite a script for scoring the second task.\nThis time Fred attempts the task tCommonRatio2a and gets it incorrect.\n\n### Fred does another task\nt.name <- \"tCommonRatio2a\"\nt.isCorrect <- \"No\"\n\n## Load Evidence Model and adjoin\n\n## Recompile\n\n## Add Evidence\n\n## Check Finding and add to history\n\n## Clean up"
  },
  {
    "objectID": "Scoring.html#answer-for-2nd-task",
    "href": "Scoring.html#answer-for-2nd-task",
    "title": "Scoring Individual Students",
    "section": "Answer for 2nd Task",
    "text": "Answer for 2nd Task\n\n### Fred does another task\nt.name <- \"tCommonRatio2a\"\nt.isCorrect <- \"No\"\n\nEMnet <- ReadNetworks(file.path(\"miniACED\",\n                                paste(EMtable[t.name,\"EM\"],\"dne\", sep=\".\")),\n                      session=sess)\nobs <- AdjoinNetwork(Fred.SM,EMnet)\n#NodeVisPos(obs$isCorrect) <- EMtable[t.name,c(\"X\",\"Y\")]\n## Fred.SM is now the Motif for the current task.\nCompileNetwork(Fred.SM)\n\nNodeFinding(obs[[1]]) <- t.isCorrect\npost <- NodeBeliefs(Fred.SMvars$SolveGeometricProblems)\nFred.History <- rbind(Fred.History,new=post)\nrownames(Fred.History)[nrow(Fred.History)] <- \n      paste(t.name,t.isCorrect,sep=\"=\")\nFred.History\n\n                        High    Medium       Low\n*Baseline*         0.1532000 0.2784000 0.5684000\ntCommonRatio1a=Yes 0.1600160 0.2893454 0.5506387\ntCommonRatio2a=No  0.1064912 0.2057332 0.6877756\n\n## Cleanup:  Delete EM and Absorb observables\nDeleteNetwork(EMnet) ## Delete EM\n#AbsorbNodes(obs)"
  },
  {
    "objectID": "Scoring.html#fred-does-another-task",
    "href": "Scoring.html#fred-does-another-task",
    "title": "Scoring Individual Students",
    "section": "Fred does another task",
    "text": "Fred does another task\n\nt.name <- \"tCommonRatio2a\"\nt.isCorrect <- \"No\"\n\n\nEMnet <- ReadNetworks(file.path(\"miniACED\",\n                paste(EMtable[t.name,\"EM\"],\"dne\",sep=\".\")),\n                session=sess)\nobs <- AdjoinNetwork(Fred.SM,EMnet)\n(NetworkAllNodes(Fred.SM)) ## Fred.SM is now the Motif for the current task.\n\n$SolveGeometricProblems\nDiscrete  Netica Node named  SolveGeometricProblems in network  Fred \n  Node is currently active.\nStates are:  High, Medium, Low \n\n$CommonRatio\nDiscrete  Netica Node named  CommonRatio in network  Fred \n  Node is currently active.\nStates are:  High, Medium, Low \n\n$ExamplesGeometric\nDiscrete  Netica Node named  ExamplesGeometric in network  Fred \n  Node is currently active.\nStates are:  High, Medium, Low \n\n$ExtendGeometric\nDiscrete  Netica Node named  ExtendGeometric in network  Fred \n  Node is currently active.\nStates are:  High, Medium, Low \n\n$ModelGeometric\nDiscrete  Netica Node named  ModelGeometric in network  Fred \n  Node is currently active.\nStates are:  High, Medium, Low \n\n$TableGeometric\nDiscrete  Netica Node named  TableGeometric in network  Fred \n  Node is currently active.\nStates are:  High, Medium, Low \n\n$isCorrect\nDiscrete  Netica Node named  isCorrect in network  Fred \n  Node is currently active.\nStates are:  Yes, No \n\n$isCorrect1\nDiscrete  Netica Node named  isCorrect1 in network  Fred \n  Node is currently active.\nStates are:  Yes, No \n\n$isCorrect2\nDiscrete  Netica Node named  isCorrect2 in network  Fred \n  Node is currently active.\nStates are:  Yes, No \n\nCompileNetwork(Fred.SM)"
  },
  {
    "objectID": "Scoring.html#task-2-continued",
    "href": "Scoring.html#task-2-continued",
    "title": "Scoring Individual Students",
    "section": "Task 2 continued",
    "text": "Task 2 continued\n\nNodeFinding(obs[[1]]) <- t.isCorrect\npost <- NodeBeliefs(Fred.SMvars$SolveGeometricProblems)\nFred.History <- rbind(Fred.History,new=post)\nrownames(Fred.History)[nrow(Fred.History)] <- paste(t.name,t.isCorrect,sep=\"=\")\nFred.History\n\n                         High    Medium       Low\n*Baseline*         0.15320002 0.2784000 0.5684000\ntCommonRatio1a=Yes 0.16001597 0.2893454 0.5506387\ntCommonRatio2a=No  0.10649122 0.2057332 0.6877756\ntCommonRatio2a=No  0.04991532 0.1159301 0.8341545\n\n\nCleanup: Delete EM and Absorb observables\n\nDeleteNetwork(EMnet) ## Delete EM\n#try(AbsorbNodes(obs))\n## Currently, there is a Netica bug with Absorb Nodes, we will leave\n##this the node in place as that is mostly harmless."
  },
  {
    "objectID": "Scoring.html#fred-logs-out",
    "href": "Scoring.html#fred-logs-out",
    "title": "Scoring Individual Students",
    "section": "Fred logs out",
    "text": "Fred logs out\nSave network to a file.\n\nWriteNetworks(Fred.SM,\"FredSM.dne\")\nDeleteNetwork(Fred.SM)\nis.active(Fred.SM)  ## No longer active in Netica space\n\n[1] FALSE\n\n\nFred logs back in\n\nFred.SM <- ReadNetworks(\"FredSM.dne\",session=sess)\nis.active(Fred.SM)\n\n[1] TRUE"
  },
  {
    "objectID": "Scoring.html#read-in-the-scores.",
    "href": "Scoring.html#read-in-the-scores.",
    "title": "Scoring Individual Students",
    "section": "Read in the scores.",
    "text": "Read in the scores.\n\nminiACED.data <- read.csv(file.path(\"miniACED\",\"miniACED-Geometric.csv\"),row.names=1)\nhead(miniACED.data)\n\n     Class Treatment Sequencing Feedback Total.Items Correct Incorrect\nS055     1         1          2        2          63       8        55\nS058     1         1          2        2          63      33        30\nS053     1         2          2        1          63      12        51\nS061     1         1          2        2          63      21        42\nS063     1         1          2        2          63      21        42\nS066     1         1          2        2          63      19        44\n     Remaining tCommonRatio1a tCommonRatio1b tCommonRatio3a tCommonRatio3b\nS055         0              1              1              2              1\nS058         0              2              2              2              1\nS053         0              1              1              1              1\nS061         0              1              1              1              1\nS063         0              1              2              2              1\nS066         0              1              2              1              1\n     tCommonRatio2a tCommonRatio2b tExamplesGeometric1a tExamplesGeometric1b\nS055              1              1                    1                    1\nS058              1              2                    2                    1\nS053              1              1                    1                    1\nS061              1              1                    1                    1\nS063              1              1                    2                    1\nS066              1              1                    2                    1\n     tExamplesGeometric3a tExamplesGeometric3b tExamplesGeometric2a\nS055                    1                    1                    1\nS058                    1                    1                    1\nS053                    1                    1                    1\nS061                    1                    1                    1\nS063                    1                    1                    1\nS066                    1                    1                    1\n     tExamplesGeometric2b tExtendGeometric1a tExtendGeometric1b\nS055                    1                  1                  1\nS058                    1                  1                  2\nS053                    1                  1                  1\nS061                    1                  2                  2\nS063                    1                  1                  2\nS066                    1                  1                  2\n     tExtendGeometric3a tExtendGeometric3b tExtendGeometric2a\nS055                  2                  1                  1\nS058                  2                  1                  2\nS053                  1                  1                  1\nS061                  1                  1                  1\nS063                  2                  2                  2\nS066                  2                  2                  1\n     tExtendGeometric2b tModelExtendTableGeometric1a\nS055                  1                            1\nS058                  1                            2\nS053                  1                            1\nS061                  2                            1\nS063                  1                            1\nS066                  1                            2\n     tModelExtendTableGeometric1b tModelExtendTableGeometric3a\nS055                            1                            1\nS058                            2                            2\nS053                            1                            2\nS061                            2                            2\nS063                            2                            1\nS066                            1                            2\n     tModelExtendTableGeometric3b tModelExtendTableGeometric2a\nS055                            1                            1\nS058                            2                            1\nS053                            1                            1\nS061                            1                            1\nS063                            2                            1\nS066                            2                            1\n     tModelExtendTableGeometric2b tTableExtendGeometric1a\nS055                            1                       1\nS058                            2                       1\nS053                            2                       1\nS061                            1                       1\nS063                            1                       2\nS066                            1                       2\n     tTableExtendGeometric1b tTableExtendGeometric3a tTableExtendGeometric3b\nS055                       1                       1                       1\nS058                       1                       1                       2\nS053                       1                       1                       2\nS061                       1                       1                       2\nS063                       1                       1                       1\nS066                       1                       1                       2\n     tTableExtendGeometric2a tTableExtendGeometric2b\nS055                       1                       2\nS058                       1                       1\nS053                       1                       1\nS061                       1                       1\nS063                       1                       1\nS066                       2                       2\n\n\nSome meta-data\n\n## Mark columns of table corresponding to tasks\nfirst.task <- 9\nlast.task <- 20 #ncol(miniACED.data)\n## Code key for numeric values\nt.vals <- c(\"No\",\"Yes\")\n\n## Pick a student, we might normally iterate over this.\nStudent.row <- 1"
  },
  {
    "objectID": "Scoring.html#setup-for-student-in-sample",
    "href": "Scoring.html#setup-for-student-in-sample",
    "title": "Scoring Individual Students",
    "section": "Setup for student in sample",
    "text": "Setup for student in sample\nCreate Student Model from Proficiency Model\n\nStudent.SM <- CopyNetworks(profModel,\"Student\")\nStudent.SMvars <- NetworkAllNodes(Student.SM)\nCompileNetwork(Student.SM)\n\nInitialize history list\n\nprior <- NodeBeliefs(Student.SMvars$SolveGeometricProblems)\nStudent.History <- matrix(prior,1,3)\nrow.names(Student.History) <- \"*Baseline*\"\ncolnames(Student.History) <- names(prior)"
  },
  {
    "objectID": "Scoring.html#now-loop-over-tasks",
    "href": "Scoring.html#now-loop-over-tasks",
    "title": "Scoring Individual Students",
    "section": "Now loop over tasks",
    "text": "Now loop over tasks\n\nfor (itask in first.task:last.task) {\n  \n  ## Look up the EM for the task, and adjoin it.\n  tid <- names(miniACED.data)[itask]\n  print(tid)\n  EMnet <- ReadNetworks(file.path(\"miniACED\",\n                                  paste(EMtable[tid,\"EM\"],\"dne\",sep=\".\")),\n                        session=sess)\n  print(sapply(NetworkAllNodes(EMnet),NodeVisPos))\n  browser()\n  obs <- AdjoinNetwork(Student.SM,EMnet)\n  CompileNetwork(Student.SM)\n\n  ## Add the evidence\n  t.val <- t.vals[miniACED.data[Student.row,itask]] #Decode integer\n  NodeFinding(obs[[1]]) <- t.val\n  \n  ## Update the history\n  post <- NodeBeliefs(Student.SMvars$SolveGeometricProblems)\n  Student.History <- rbind(Student.History,new=post)\n  rownames(Student.History)[nrow(Student.History)] <- paste(tid,t.val,sep=\"=\")\n\n  ## Cleanup, Delete EM and Absob Observables\n  DeleteNetwork(EMnet)\n  #try(AbsorbNodes(obs)) # Still broken\n}\n\n[1] \"tCommonRatio1a\"\n  isCorrect\nx         0\ny         0\nCalled from: eval(expr, envir, enclos)\ndebug at <text>#11: obs <- AdjoinNetwork(Student.SM, EMnet)\ndebug at <text>#12: CompileNetwork(Student.SM)\ndebug at <text>#15: t.val <- t.vals[miniACED.data[Student.row, itask]]\ndebug at <text>#16: NodeFinding(obs[[1]]) <- t.val\ndebug at <text>#19: post <- NodeBeliefs(Student.SMvars$SolveGeometricProblems)\ndebug at <text>#20: Student.History <- rbind(Student.History, new = post)\ndebug at <text>#21: rownames(Student.History)[nrow(Student.History)] <- paste(tid, \n    t.val, sep = \"=\")\ndebug at <text>#24: DeleteNetwork(EMnet)\ndebug at <text>#4: tid <- names(miniACED.data)[itask]\ndebug at <text>#5: print(tid)\n[1] \"tCommonRatio1b\"\ndebug at <text>#6: EMnet <- ReadNetworks(file.path(\"miniACED\", paste(EMtable[tid, \n    \"EM\"], \"dne\", sep = \".\")), session = sess)\ndebug at <text>#9: print(sapply(NetworkAllNodes(EMnet), NodeVisPos))\n  isCorrect\nx         0\ny         0\ndebug at <text>#10: browser()\ndebug at <text>#11: obs <- AdjoinNetwork(Student.SM, EMnet)\ndebug at <text>#12: CompileNetwork(Student.SM)\ndebug at <text>#15: t.val <- t.vals[miniACED.data[Student.row, itask]]\ndebug at <text>#16: NodeFinding(obs[[1]]) <- t.val\ndebug at <text>#19: post <- NodeBeliefs(Student.SMvars$SolveGeometricProblems)\ndebug at <text>#20: Student.History <- rbind(Student.History, new = post)\ndebug at <text>#21: rownames(Student.History)[nrow(Student.History)] <- paste(tid, \n    t.val, sep = \"=\")\ndebug at <text>#24: DeleteNetwork(EMnet)\ndebug at <text>#4: tid <- names(miniACED.data)[itask]\ndebug at <text>#5: print(tid)\n[1] \"tCommonRatio3a\"\ndebug at <text>#6: EMnet <- ReadNetworks(file.path(\"miniACED\", paste(EMtable[tid, \n    \"EM\"], \"dne\", sep = \".\")), session = sess)\ndebug at <text>#9: print(sapply(NetworkAllNodes(EMnet), NodeVisPos))\n  isCorrect\nx         0\ny         0\ndebug at <text>#10: browser()\ndebug at <text>#11: obs <- AdjoinNetwork(Student.SM, EMnet)\ndebug at <text>#12: CompileNetwork(Student.SM)\ndebug at <text>#15: t.val <- t.vals[miniACED.data[Student.row, itask]]\ndebug at <text>#16: NodeFinding(obs[[1]]) <- t.val\ndebug at <text>#19: post <- NodeBeliefs(Student.SMvars$SolveGeometricProblems)\ndebug at <text>#20: Student.History <- rbind(Student.History, new = post)\ndebug at <text>#21: rownames(Student.History)[nrow(Student.History)] <- paste(tid, \n    t.val, sep = \"=\")\ndebug at <text>#24: DeleteNetwork(EMnet)\ndebug at <text>#4: tid <- names(miniACED.data)[itask]\ndebug at <text>#5: print(tid)\n[1] \"tCommonRatio3b\"\ndebug at <text>#6: EMnet <- ReadNetworks(file.path(\"miniACED\", paste(EMtable[tid, \n    \"EM\"], \"dne\", sep = \".\")), session = sess)\ndebug at <text>#9: print(sapply(NetworkAllNodes(EMnet), NodeVisPos))\n  isCorrect\nx         0\ny         0\ndebug at <text>#10: browser()\ndebug at <text>#11: obs <- AdjoinNetwork(Student.SM, EMnet)\ndebug at <text>#12: CompileNetwork(Student.SM)\ndebug at <text>#15: t.val <- t.vals[miniACED.data[Student.row, itask]]\ndebug at <text>#16: NodeFinding(obs[[1]]) <- t.val\ndebug at <text>#19: post <- NodeBeliefs(Student.SMvars$SolveGeometricProblems)\ndebug at <text>#20: Student.History <- rbind(Student.History, new = post)\ndebug at <text>#21: rownames(Student.History)[nrow(Student.History)] <- paste(tid, \n    t.val, sep = \"=\")\ndebug at <text>#24: DeleteNetwork(EMnet)\ndebug at <text>#4: tid <- names(miniACED.data)[itask]\ndebug at <text>#5: print(tid)\n[1] \"tCommonRatio2a\"\ndebug at <text>#6: EMnet <- ReadNetworks(file.path(\"miniACED\", paste(EMtable[tid, \n    \"EM\"], \"dne\", sep = \".\")), session = sess)\ndebug at <text>#9: print(sapply(NetworkAllNodes(EMnet), NodeVisPos))\n  isCorrect\nx         0\ny         0\ndebug at <text>#10: browser()\ndebug at <text>#11: obs <- AdjoinNetwork(Student.SM, EMnet)\ndebug at <text>#12: CompileNetwork(Student.SM)\ndebug at <text>#15: t.val <- t.vals[miniACED.data[Student.row, itask]]\ndebug at <text>#16: NodeFinding(obs[[1]]) <- t.val\ndebug at <text>#19: post <- NodeBeliefs(Student.SMvars$SolveGeometricProblems)\ndebug at <text>#20: Student.History <- rbind(Student.History, new = post)\ndebug at <text>#21: rownames(Student.History)[nrow(Student.History)] <- paste(tid, \n    t.val, sep = \"=\")\ndebug at <text>#24: DeleteNetwork(EMnet)\ndebug at <text>#4: tid <- names(miniACED.data)[itask]\ndebug at <text>#5: print(tid)\n[1] \"tCommonRatio2b\"\ndebug at <text>#6: EMnet <- ReadNetworks(file.path(\"miniACED\", paste(EMtable[tid, \n    \"EM\"], \"dne\", sep = \".\")), session = sess)\ndebug at <text>#9: print(sapply(NetworkAllNodes(EMnet), NodeVisPos))\n  isCorrect\nx         0\ny         0\ndebug at <text>#10: browser()\ndebug at <text>#11: obs <- AdjoinNetwork(Student.SM, EMnet)\ndebug at <text>#12: CompileNetwork(Student.SM)\ndebug at <text>#15: t.val <- t.vals[miniACED.data[Student.row, itask]]\ndebug at <text>#16: NodeFinding(obs[[1]]) <- t.val\ndebug at <text>#19: post <- NodeBeliefs(Student.SMvars$SolveGeometricProblems)\ndebug at <text>#20: Student.History <- rbind(Student.History, new = post)\ndebug at <text>#21: rownames(Student.History)[nrow(Student.History)] <- paste(tid, \n    t.val, sep = \"=\")\ndebug at <text>#24: DeleteNetwork(EMnet)\ndebug at <text>#4: tid <- names(miniACED.data)[itask]\ndebug at <text>#5: print(tid)\n[1] \"tExamplesGeometric1a\"\ndebug at <text>#6: EMnet <- ReadNetworks(file.path(\"miniACED\", paste(EMtable[tid, \n    \"EM\"], \"dne\", sep = \".\")), session = sess)\ndebug at <text>#9: print(sapply(NetworkAllNodes(EMnet), NodeVisPos))\n  isCorrect\nx         0\ny         0\ndebug at <text>#10: browser()\ndebug at <text>#11: obs <- AdjoinNetwork(Student.SM, EMnet)\ndebug at <text>#12: CompileNetwork(Student.SM)\ndebug at <text>#15: t.val <- t.vals[miniACED.data[Student.row, itask]]\ndebug at <text>#16: NodeFinding(obs[[1]]) <- t.val\ndebug at <text>#19: post <- NodeBeliefs(Student.SMvars$SolveGeometricProblems)\ndebug at <text>#20: Student.History <- rbind(Student.History, new = post)\ndebug at <text>#21: rownames(Student.History)[nrow(Student.History)] <- paste(tid, \n    t.val, sep = \"=\")\ndebug at <text>#24: DeleteNetwork(EMnet)\ndebug at <text>#4: tid <- names(miniACED.data)[itask]\ndebug at <text>#5: print(tid)\n[1] \"tExamplesGeometric1b\"\ndebug at <text>#6: EMnet <- ReadNetworks(file.path(\"miniACED\", paste(EMtable[tid, \n    \"EM\"], \"dne\", sep = \".\")), session = sess)\ndebug at <text>#9: print(sapply(NetworkAllNodes(EMnet), NodeVisPos))\n  isCorrect\nx         0\ny         0\ndebug at <text>#10: browser()\ndebug at <text>#11: obs <- AdjoinNetwork(Student.SM, EMnet)\ndebug at <text>#12: CompileNetwork(Student.SM)\ndebug at <text>#15: t.val <- t.vals[miniACED.data[Student.row, itask]]\ndebug at <text>#16: NodeFinding(obs[[1]]) <- t.val\ndebug at <text>#19: post <- NodeBeliefs(Student.SMvars$SolveGeometricProblems)\ndebug at <text>#20: Student.History <- rbind(Student.History, new = post)\ndebug at <text>#21: rownames(Student.History)[nrow(Student.History)] <- paste(tid, \n    t.val, sep = \"=\")\ndebug at <text>#24: DeleteNetwork(EMnet)\ndebug at <text>#4: tid <- names(miniACED.data)[itask]\ndebug at <text>#5: print(tid)\n[1] \"tExamplesGeometric3a\"\ndebug at <text>#6: EMnet <- ReadNetworks(file.path(\"miniACED\", paste(EMtable[tid, \n    \"EM\"], \"dne\", sep = \".\")), session = sess)\ndebug at <text>#9: print(sapply(NetworkAllNodes(EMnet), NodeVisPos))\n  isCorrect\nx         0\ny         0\ndebug at <text>#10: browser()\ndebug at <text>#11: obs <- AdjoinNetwork(Student.SM, EMnet)\ndebug at <text>#12: CompileNetwork(Student.SM)\ndebug at <text>#15: t.val <- t.vals[miniACED.data[Student.row, itask]]\ndebug at <text>#16: NodeFinding(obs[[1]]) <- t.val\ndebug at <text>#19: post <- NodeBeliefs(Student.SMvars$SolveGeometricProblems)\ndebug at <text>#20: Student.History <- rbind(Student.History, new = post)\ndebug at <text>#21: rownames(Student.History)[nrow(Student.History)] <- paste(tid, \n    t.val, sep = \"=\")\ndebug at <text>#24: DeleteNetwork(EMnet)\ndebug at <text>#4: tid <- names(miniACED.data)[itask]\ndebug at <text>#5: print(tid)\n[1] \"tExamplesGeometric3b\"\ndebug at <text>#6: EMnet <- ReadNetworks(file.path(\"miniACED\", paste(EMtable[tid, \n    \"EM\"], \"dne\", sep = \".\")), session = sess)\ndebug at <text>#9: print(sapply(NetworkAllNodes(EMnet), NodeVisPos))\n  isCorrect\nx         0\ny         0\ndebug at <text>#10: browser()\ndebug at <text>#11: obs <- AdjoinNetwork(Student.SM, EMnet)\ndebug at <text>#12: CompileNetwork(Student.SM)\ndebug at <text>#15: t.val <- t.vals[miniACED.data[Student.row, itask]]\ndebug at <text>#16: NodeFinding(obs[[1]]) <- t.val\ndebug at <text>#19: post <- NodeBeliefs(Student.SMvars$SolveGeometricProblems)\ndebug at <text>#20: Student.History <- rbind(Student.History, new = post)\ndebug at <text>#21: rownames(Student.History)[nrow(Student.History)] <- paste(tid, \n    t.val, sep = \"=\")\ndebug at <text>#24: DeleteNetwork(EMnet)\ndebug at <text>#4: tid <- names(miniACED.data)[itask]\ndebug at <text>#5: print(tid)\n[1] \"tExamplesGeometric2a\"\ndebug at <text>#6: EMnet <- ReadNetworks(file.path(\"miniACED\", paste(EMtable[tid, \n    \"EM\"], \"dne\", sep = \".\")), session = sess)\ndebug at <text>#9: print(sapply(NetworkAllNodes(EMnet), NodeVisPos))\n  isCorrect\nx         0\ny         0\ndebug at <text>#10: browser()\ndebug at <text>#11: obs <- AdjoinNetwork(Student.SM, EMnet)\ndebug at <text>#12: CompileNetwork(Student.SM)\ndebug at <text>#15: t.val <- t.vals[miniACED.data[Student.row, itask]]\ndebug at <text>#16: NodeFinding(obs[[1]]) <- t.val\ndebug at <text>#19: post <- NodeBeliefs(Student.SMvars$SolveGeometricProblems)\ndebug at <text>#20: Student.History <- rbind(Student.History, new = post)\ndebug at <text>#21: rownames(Student.History)[nrow(Student.History)] <- paste(tid, \n    t.val, sep = \"=\")\ndebug at <text>#24: DeleteNetwork(EMnet)\ndebug at <text>#4: tid <- names(miniACED.data)[itask]\ndebug at <text>#5: print(tid)\n[1] \"tExamplesGeometric2b\"\ndebug at <text>#6: EMnet <- ReadNetworks(file.path(\"miniACED\", paste(EMtable[tid, \n    \"EM\"], \"dne\", sep = \".\")), session = sess)\ndebug at <text>#9: print(sapply(NetworkAllNodes(EMnet), NodeVisPos))\n  isCorrect\nx         0\ny         0\ndebug at <text>#10: browser()\ndebug at <text>#11: obs <- AdjoinNetwork(Student.SM, EMnet)\ndebug at <text>#12: CompileNetwork(Student.SM)\ndebug at <text>#15: t.val <- t.vals[miniACED.data[Student.row, itask]]\ndebug at <text>#16: NodeFinding(obs[[1]]) <- t.val\ndebug at <text>#19: post <- NodeBeliefs(Student.SMvars$SolveGeometricProblems)\ndebug at <text>#20: Student.History <- rbind(Student.History, new = post)\ndebug at <text>#21: rownames(Student.History)[nrow(Student.History)] <- paste(tid, \n    t.val, sep = \"=\")\ndebug at <text>#24: DeleteNetwork(EMnet)"
  },
  {
    "objectID": "Scoring.html#now-look-at-the-scoring-history.",
    "href": "Scoring.html#now-look-at-the-scoring-history.",
    "title": "Scoring Individual Students",
    "section": "Now look at the scoring history.",
    "text": "Now look at the scoring history.\n\nStudent.History\n\n                                High     Medium       Low\n*Baseline*              0.1532000154 0.27840000 0.5684000\ntCommonRatio1a=No       0.0693975762 0.14382692 0.7867755\ntCommonRatio1b=No       0.0131133273 0.04543132 0.9414554\ntCommonRatio3a=Yes      0.0576437376 0.12699647 0.8153598\ntCommonRatio3b=No       0.0383302718 0.09589107 0.8657787\ntCommonRatio2a=No       0.0122262547 0.05103555 0.9367382\ntCommonRatio2b=No       0.0033196749 0.03242403 0.9642563\ntExamplesGeometric1a=No 0.0010064315 0.02298103 0.9760125\ntExamplesGeometric1b=No 0.0006250255 0.02056840 0.9788066\ntExamplesGeometric3a=No 0.0006051398 0.02043075 0.9789641\ntExamplesGeometric3b=No 0.0005891956 0.02031317 0.9790976\ntExamplesGeometric2a=No 0.0005483013 0.01998808 0.9794636\ntExamplesGeometric2b=No 0.0005246418 0.01979495 0.9796804"
  },
  {
    "objectID": "Scoring.html#weight-of-evidence-1",
    "href": "Scoring.html#weight-of-evidence-1",
    "title": "Scoring Individual Students",
    "section": "Weight of Evidence",
    "text": "Weight of Evidence\nGood (1985)\nH is binary hypothesis, e.g., Proficiency > Medium\nE is evidence for hypothesis\nWeight of Evidence (WOE) is\n\\[ W(H:E) = \\log \\frac{P(E|H)}{P(E|\\overline{H})} =\n\\log  \\frac{P(H|E)}{P(\\overline{H}|E)} -\n\\log  \\frac{P(H)}{P(\\overline{H})} \\]"
  },
  {
    "objectID": "Scoring.html#conditional-weight-of-evidence",
    "href": "Scoring.html#conditional-weight-of-evidence",
    "title": "Scoring Individual Students",
    "section": "Conditional Weight of Evidence",
    "text": "Conditional Weight of Evidence\n\\[ W(H: E_2 | E_1) = \\log  \\frac{P(E_2|H,E_1)}{P(E_2|\\overline{H},E_1)}\n\\] Additive properties\n\\[ W(H: E_1, E2) = W(H: E_1) + W(H: E_2|E_1) \\]\nOrder senstive (evidence seen earlier is worth more)\nWOE Balance Sheet:"
  },
  {
    "objectID": "Scoring.html#now-examine-scoring-history",
    "href": "Scoring.html#now-examine-scoring-history",
    "title": "Scoring Individual Students",
    "section": "Now examine scoring history",
    "text": "Now examine scoring history\n\nwoeBal(Student.History,c(\"High\",\"Medium\"),\"Low\",\n       title=paste(\"Evidence Balance Sheet for \",\n                   rownames(miniACED.data)[Student.row]))"
  },
  {
    "objectID": "Scoring.html#for-more-information",
    "href": "Scoring.html#for-more-information",
    "title": "Scoring Individual Students",
    "section": "For More information",
    "text": "For More information\n\nhelp(RNetica)\nhelp(package=\"RNetica\")\nhelp(CPTtools)\nhelp(package=\"CPTtools\")"
  },
  {
    "objectID": "Session3.html",
    "href": "Session3.html",
    "title": "Peanut Tutorial",
    "section": "",
    "text": "Bayesian Networks in Educational Assessment\nTutorial\nSession III: __ __ Bayes Net with R\nDuanli Yan, Diego Zapata, ETS\nRussell Almond, FSU\n2021 NCME Tutorial: Bayesian Networks in Educational Assessment\nSESSION __ __ TOPIC __ __ PRESENTERS\nSession 1 : Evidence Centered Design Diego Zapata Bayesian Networks\nSession 2 : Bayes Net Applications Duanli Yan & ACED: ECD in Action Russell Almond\nSession 3 : Bayes Nets with R Russell Almond & Duanli Yan\nSession 4 : Refining Bayes Nets with Duanli Yan & Data Russell Almond\n\nRNetica\n\n\nQuick Start Guide\nScoring A Student\nRNetica Quick Start\n\n\nDownloading\n\nhttp://pluto.coe.fsu.edu/RNetica/\nFour Packages:\n\nRNetica – R to Netica link\nCPTtools – Design patterns for CPTs\nPeanut/PNetica -- Object-Oriented Parameterized Network\n\nSource & binary version (Win 64, Mac OS X)\n\nBinary versions include Netica.dll/libNetica.so\n\nIn RStudio select “Package Archive” rather than CRAN\n\nSource version need to download from http://www.norsys.com/ first\n\nSee INSTALLATION\n\n\n\nRNetica Quick Start\n\n\nLicense\n\nR – GPL-3 (Free and open source)\nRNetica – Artistic (Free and open source)\nNetica.dll/libNetica.so – Commercial (open API, but not open source)\n\nFree Student/Demo version\n\nLimited number of nodes\nLimited usage (education, evaluation of Netica)\n\nPaid version (see http://www.norsys.com/ for price information)\n\nNeed to purchase API not GUI version of Netica\nMay want both (use GUI to visualize networks build in RNetica)\n\n\nCPTtools – Artistic (Free and open source), does not depend on Netica\n\nRNetica Quick Start\n\n\nInstalling the License Key\n\nWhen you purchase a license, Norsys will send you a license key. Something that looks like: “+Course/FloridaSU/Ex15-05-30,120,310/XXXXX” (Where I’ve obscured the last 5 security digits)\nTo install the license key, start R in your project directory and type:\n\n\nNeticaLicenseKey <- “+Course/FloridaSU/Ex15-05-30,120,310/XXXXX”\n\n\nq(“yes”)\n\n\nRestart R and type\n\n\nlibrary(RNetica)\n\n\nIf license key is not installed, then you will get the limited/student mode. Most of these examples will run\n\nRNetica Quick Start\n\n\nThe R heap and the Netica heap\nR and Netica have two different workspaces (memory heaps)\nR workspace is saved and restored automatically when you quick and restart R.\nNetica heap must be reconnected manually.\nRNetica Quick Start\n\n\nActive and Inactive pointers\nWhen RNetica creates/finds a Netica object it creates a corresponding R object\nIf the R object is active then it points to the Netica object, and the Netica object points back at it\nIf the pointer gets broken (saving & restarting R, deleting the network/node) then the R object becomes inactive.\nThe function is.active(nodeOrNet) test to see if the node/net is active\nRNetica Quick Start\n\n\nMini-ACED Proficiency model\nSubset of ACED network (Shute, Hansen & Almond (2008); http://ecd.ralmond.net/ecdwiki/ACED )\nProficiency Model subset:\n\nRNetica Quick Start\n\n\nMini-ACED EM Fragments\nAll ACED tasks were scored correct/incorrect\nEach evidence model is represented by a fragment consisting of observables with stub  edges indicating where it should be adjoined with the network.\n\n\nCommon Ratio Easy\nModel Extend Table Hard\nRNetica Quick Start\n\n\nTask to EM map\nNeed a table to tell us which EM to use with which task\n\n\n\nTask ID\nEM Filename\nX\nY\n\n\n\n\ntCommonRatio1b\nCommonRatioEasyEM\n108\n414\n\n\ntCommonRatio2a\nCommonRatioMedEM\n108\n534\n\n\ntCommonRatio2b\nCommonRatioMedEM\n108\n654\n\n\ntCommonRatio3a\nCommonRatioHardEM\n108\n774\n\n\ntCommonRatio3b\nCommonRatioHardEM\n108\n894\n\n\ntExamplesGeometric1a\nExamplesEasyEM\n342\n294\n\n\ntExamplesGeometric1b\nExamplesEasyEM\n342\n414\n\n\n\n\n\n\n\n\n\nRNetica Quick Start\n\n\nScoring Script\nFollow along using the script found in ScoringScript.R in the miniACED folder.\nDon’t forget to setwd() to the miniACED folder (as it needs to find its networks).\nDon’t forget to set the license key before issuing library(RNetica) command.\nRNetica Quick Start\n\n\nReloading Nets and Nodes\n## Scoring Script\n## Preliminaries\nlibrary(RNetica)\nlibrary(CPTtools)\n## Read in network – Do this every time R is restarted\nprofModel <- ReadNetworks(“miniACEDPnet.dne”)\n## If  profModels  already exists could also use\n## Reconnect nodes – Do this every time R is restarted\nallNodes <- NetworkAllNodes(profModel)\nsgp <- allNodes$SolveGeometricProblems\nprofNodes <- NetworkNodesInSet(profModel,“Proficiencies”)\nRNetica Quick Start\n\n\nAside 1: Node Sets\n\nNetica defines a node set functionality which\n\nAdds a collection of labels (sets) to each node\nDefines a collection of nodes with that label\n\nNetica GUI really only offers the opportunity to color nodes by set\nRNetica can loop over node sets (lists of nodes)\n## Node Sets\nNetworkNodeSets(profModel)\nNetworkNodesInSet(profModel,“pnodes”)\nNodeSets(sgp)\n## These are all settable\nNodeSets(sgp) <- c(NodeSets(sgp),“HighLevel”)\nNodeSets(sgp)\n\nRNetica Quick Start\n\n\nAside 2: RNetica Functions\n## Querying Nodes\nNodeStates(sgp) #List states\nNodeParents(sgp) #List parents\nNodeLevels(sgp) #List numeric values associated with states\nNodeProbs(sgp) # Conditional Probability Table (as array)\nsgp[] # Conditional Probability Table (as data frame)\n## These are all settable (can be used on RHS of <-) for \n## model construction\n## Inference\nCompileNetwork(profModel) #Lightning bolt on GUI\n## Must do this before inference\n## Recompiling an already compiled network is harmless\nRNetica Quick Start\n\n\nAside 2: Inference\n## Enter Evidence by setting values for these functions\nNodeValue(sgp) #View or set the value\nNodeLikelihood(sgp) #Virtual evidence\n## Query beliefs\nNodeBeliefs(sgp) #Current probability (given entered evidence)\nNodeExpectedValue(sgp) #If node has values, EAP\n## These aren’t settable\n## Retract Evidence\nRetractNodeFinding(profNodes$ExamplesGeometric)\nRetractNetFindings(profModel)\nRNetica Quick Start\n\n\nAside 2: Example\n## Enter Evidence\nNodeValue(profNodes$CommonRatio) <- “Medium”\n## Enter Evidence “Not Low” (“High or Medium”)\nNodeLikelihood(profNodes$ExamplesGeometric) <- c(1,1,0)\nNodeBeliefs(sgp) #Current probability (given entered evidence)\nNodeExpectedValue(sgp) #If node has values, EAP\n## Retract Evidence\nRetractNetFindings(profModel)\n## Many more examples\nhelp(RNetica)\nRNetica Quick Start\n\n\nBack to work\nLoad the evidence model table\nRow names are task IDs\nEM column contains evidence model name\nEM filename has suffix “.dne” attached.\n## Read in task->evidence model mapping\nEMtable <- read.csv(“MiniACEDEMTable.csv”,row.names=1,\nas.is=2) #Keep EM names as strings\nhead(EMtable)\nRNetica Quick Start\n\n\nA student walks into the test center …\n\nStudent gives the name “Fred”\nStudent is the right grade/age for ACED (8th or 9th grader, pre-algebra)\nBayes net has three states\n\nFred logs into ACED\nFred attempts the task tCommonRatio1a and gets it right\nFred attempts the task tCommonRatio2a and gets it wrong\n\n\nRNetica Quick Start\n\n\nStart a new student\n## Copy the master proficiency model\n## to make student model\nFred.SM <- CopyNetworks(profModel,“Fred”)\nFred.SMvars <- NetworkAllNodes(Fred.SM)\nCompileNetwork(Fred.SM)\n## Setup score history\nprior <- NodeBeliefs(Fred.SMvars$SolveGeometricProblems)\nFred.History <- matrix(prior,1,3)\nrow.names(Fred.History) <- “*Baseline*”\ncolnames(Fred.History) <- names(prior)\nFred.History\nRNetica Quick Start\n\n\nScore 1st Task\n### Fred does a task\nt.name <- “tCommonRatio1a”\nt.isCorrect <- “Yes”\n## Adjoin SM and EM\nEMnet <- ReadNetworks(paste(EMtable[t.name,“EM”],“dne”,sep=“.”))\nobs <- AdjoinNetwork(Fred.SM,EMnet)\nNetworkAllNodes(Fred.SM)\n## Fred.SM is now the Motif for the current task.\nCompileNetwork(Fred.SM)\n## Enter finding\nNodeFinding(obs$isCorrect) <- t.isCorrect\nRNetica Quick Start\n\n\nStats and Cleanup for 1st task\n## Calculate statistics of interest\npost <- NodeBeliefs(Fred.SMvars$SolveGeometricProblems)\nFred.History <- rbind(Fred.History,new=post)\nrownames(Fred.History)[nrow(Fred.History)] <- paste(t.name,t.isCorrect,sep=“=”)\nFred.History\n## Cleanup and Observable no longer needed, so absorb it:\nDeleteNetwork(EMnet) ## Delete EM\n## AbsorbNodes(obs)\n## Currently, there is a  Netica  bug with Absorb Nodes, we will leave\n## this node in place as that is mostly harmless.\nRNetica Quick Start\n\n\n2nd Task\n### Fred does another task\nt.name <- “tCommonRatio2a”\nt.isCorrect <- “No”\nEMnet <- ReadNetworks(paste(EMtable[t.name,“EM”],“dne”,sep=“.”))\nobs <- AdjoinNetwork(Fred.SM,EMnet)\nNetworkAllNodes(Fred.SM)\n## Fred.SM is now the Motif for the current task.\nCompileNetwork(Fred.SM)\nNodeFinding(obs[[1]]) <- t.isCorrect\npost <- NodeBeliefs(Fred.SMvars$SolveGeometricProblems)\nFred.History <- rbind(Fred.History,new=post)\nrownames(Fred.History)[nrow(Fred.History)] <-\npaste(t.name,t.isCorrect,sep=“=”)\nFred.History\n# # Cleanup: Delete EM and Absorb observables\nDeleteNetwork(EMnet) ## Delete EM\n## AbsorbNodes(obs)\nRNetica Quick Start\n\n\nSave and Restore\n## Fred logs out\nWriteNetworks(Fred.SM,“FredSM.dne”)\nDeleteNetwork(Fred.SM)\nis.active(Fred.SM)\n## No longer active in  Netica  space\n## Fred logs back in\nFred.SM <- ReadNetworks(“FredSM.dne”)\nis.active(Fred.SM)\nRNetica Quick Start\n\n\nGetting Serious\n\nACED field test has 230 students attempt all 63 tasks.\nFile miniACED-Geometric contains 30 task subset\n\nThere may be data registration issues here, don’t publish using these data before checking with me for an update\n\nEach row is one student Record\nLets score the first student\n\nAnd build a score history\n\n\nRNetica Quick Start\n\n\nSetup for mini-ACED\nminiACED.data <- read.csv(“miniACED-Geometric.csv”,row.names=1)\nhead(miniACED.data)\nnames(miniACED.data)\n## Mark columns of table corresponding to tasks\nfirst.task <- 9\nlast.task <- ncol(miniACED.data)\n## Code key for numeric values\nt.vals <- c(“No”,“Yes”)\nRNetica Quick Start\n\n\nSetup new Student\n## Pick a student, we might normally iterate over this.\nStudent.row <- 1\n## Setup for student in sample\n## Create Student Model from Proficiency Model\nStudent.SM <- CopyNetworks(profModel,“Student”)\nStudent.SMvars <- NetworkAllNodes(Student.SM)\nCompileNetwork(Student.SM)\n## Initialize history list\nprior <- NodeBeliefs(Student.SMvars$SolveGeometricProblems)\nStudent.History <- matrix(prior,1,3)\nrow.names(Student.History) <- “*Baseline*”\ncolnames(Student.History) <- names(prior)\nRNetica Quick Start\n\n\nLoop Part 1: Add Evidence\n## Now loop over tasks\nfor (itask in first.task:last.task) {\n ## Look up the EM for the task, and adjoin it.\ntid <- names(miniACED.data)[itask]\nEMnet <- ReadNetworks(paste(EMtable[tid,“EM”],“dne”,sep=“.”))\nobs <- AdjoinNetwork(Student.SM,EMnet)\nCompileNetwork(Student.SM)\n## Add the evidence\nt.val <- t.vals[miniACED.data[Student.row,itask]] #Decode integer\nNodeFinding(obs[[1]]) <- t.val\nRNetica Quick Start\n\n\nLoop Part 2: Capture Statistics\n## Update the history\npost <- NodeBeliefs(Student.SMvars$SolveGeometricProblems)\nStudent.History <- rbind(Student.History,new=post)\nrownames(Student.History)[nrow(Student.History)] <- paste(tid,t.val,sep=“=”)\n## Cleanup, Delete EM and  Absob  Observables\nDeleteNetwork(EMnet)\n##  AbsorbNodes ( obs ) # Still broken\n}\nRNetica Quick Start\n\n\nWeight of Evidence\nGood (1985)\nH is binary hypothesis, e.g., Proficiency > Medium\nE is evidence for hypothesis\nWeight of Evidence (WOE) is"
  },
  {
    "objectID": "Resources.html",
    "href": "Resources.html",
    "title": "Resources",
    "section": "",
    "text": "There are a number of packages that will do the basic Bayesian network computations. For the purposes of this tutorial, we are using NeticaⓇ. Netica is available in two versions: a graphical user interface (GUI) version and an application programmers interface (API). We will use both in this class.\nNetica also comes in both a free (but not open source) version and a paid version. The paid version is used by purchasing an unlock code from Norsys. The free version is specifically for training and evaluation. It is limited in the size of the networks, but it has sufficient capacity for most of the exercises in this tutorial.\n\nGo to https://norsys.com and download the latest version of Netica.exe.\nUnix/linux users: Netica.exe runs without major problems under Wine.\nMac OS Intell – I have built a wineskin version of Netica.exe.\nMac OS ARM – ???\n\nThe R package RNetica provides an R binding of the Netica API (hence, it requires the API and not GUI license). RNetica is available at https://ralmond.r-universe.dev/ (source code is at https://github.com/ralmond/).\nIf you have not already done so, we recommend downloading R Studio, in the process of installing R Studio, you will need to install R itself (<https://cloud.r-project.org/).\nOnce you have R installed, you can install RNetica and running related packages by running the following code:\n\nif (!require('PNetica')) \n  install.packages(c('CPTtootls','RNetica','Peanut','PNetica'),\n                   repos = c('https://ralmond.r-universe.dev',    'https://cloud.r-project.org'))\n\nLoading required package: PNetica\n\n\nLoading required package: RNetica\n\n\nLoading required package: CPTtools\n\n\nLoading required package: futile.logger\n\n\nLoading required package: Peanut\n\n\nThis bundle contains the following packages:\n\nCPTtools — A collection of functions for making conditional probability tables. (Does not depend on Netica.)\nRNetica — An R binding of the Netica API. Note that the installer downloads and installs Netica, so cognizant of the Netica License.\nPeanut — An object oriented layer for working with parameterized networks (PNets).\n\nPNetica — All of the Netica specific implementation of the Peanut protocol.\n\nThe intention is that Peanut (and CPTtools) are open implementation protocols that are independent of the specific Bayes net implementation. I’m currently looking for volunteers to build the equivalent of PNetica for other Bayes net engines."
  },
  {
    "objectID": "Session2.html",
    "href": "Session2.html",
    "title": "Peanut Tutorial",
    "section": "",
    "text": "Bayesian Networks in Educational Assessment\nTutorial\nSession II: __ __ Bayes Net Applications \n__ __ ACED: ECD in Action\nDuanli Yan, Diego Zapata, ETS\nRussell Almond, FSU\n2021 NCME Tutorial: Bayesian Networks in Educational Assessment\nSESSION __ __ TOPIC __ __ PRESENTERS\nSession 1 : Evidence Centered Design Diego Zapata Bayesian Networks\nSession 2 : Bayes Net Applications Duanli Yan & ACED: ECD in Action Russell Almond\nSession 3 : Refining Bayes Nets with Russell Almond & Data Duanli Yan\nSession 4 : Bayes Nets with R Duanli Yan & Russell Almond\n\n1. Discrete Item Response Theory (IRT)\nProficiency Model\nTask/Evidence Models\nAssembly Model\nSome Numbers\n\n\nIRT Proficiency Model\n\nThere is one proficiency varaible,  . (Sometimes called an “ability parameter”, but we reserve the term parameter for quantites which are not person specific.)\n takes on values {-2, -1, 0, 1, 2} with prior probabilities of (0.1, 0.2, 0.4, 0.2, 0.1) (Triangular distribution).\nObservable outcome variables are all independent given \nGoal is to draw inferences about \n\nRank order students by \nClassify students according to  above or below a cut point\n\n\n\n\nIRT Task/Evidence Model\nTasks yield an work product which can be unambiguously scored right / wrong .\nEach task has a single observable outcome variable.\nTasks are often called items,  although the common usage often blurs the distinction between the presentation of the item and the outcome variable.\n\n\nIRT (Rasch) Evidence Model\n\nLet X j _ _ be observable outcome variable from Task j\nP(X j _ =right | _  ,   j _ ) _ =\n\n_ _ j  is the difficulty of the item.\n\nCan crank through the formula for each of the five values of  to get values for Conditional Probability Tables (CPT)\n\n\n\nIRT Assembly Model\n5 items\nIncreasing difficulty:\n _ _  _ {-1.5, -0.75, 0, 0.75, 1.5}. _\nAdaptive presentation of items\n\n\nConditional Probability Tables\n\n\n\n\nPrior\nItem 1\nItem 2\nItem 3\nItem 4\nItem 5\n\n\n\n\n-2\n0.1\n0.3775\n0.2227\n0.1192\n0.0601\n0.0293\n\n\n-1\n0.2\n0.6225\n0.4378\n0.2689\n0.1480\n0.0759\n\n\n0\n0.4\n0.8176\n0.6792\n0.5000\n0.3208\n0.1824\n\n\n1\n0.2\n0.9241\n0.8520\n0.7311\n0.5622\n0.3775\n\n\n2\n0.1\n0.9707\n0.9399\n0.8088\n0.7773\n0.6225\n\n\n\n\n\nProblems Set 1\n\nAssume  =1, what is expected score (sum X j )\nCalculate P(  _ |X_ 1 = right ), E(  _ |X_ 1 = right )\nCalculate P(  _ |X_ 5 = right ), E(  _ |X_ 5 = right )\nScore three students who have the following observable patterns (Tasks 1--5):\n\n1,1,1,0,0\n1,0,0,1,1\n1,1,1,0,1\n\n\n5. Suppose we have observed for a given student X 2 = right and X 3 = right , what is the next best item to present (hint, look for expected probabilities closest to .5,.5\n6. Same thing, with X 2 = right and X 3 = wrong\n7. Same thing, with X 2 = wrong and X 3 = wrong\n\n\n2. “Context” effect –Testlets\n\nStandard assumption of conditional independence of observable variables given Proficiency Variables\nViolation\n\nShared stimulus\nContext\nSpecial knowledge\nShared Work Product\nSequential dependencies\nScoring Dependencies (Multi-step problem)\n\nTestlets (Wainer & Kiely, 1987)\nViolation results in overestimating the evidential value of observables for Proficiency Variables\n\n\n\n“Context” effect – Variables\n\nContext variable – A parent variable introduced to handle conditional dependence among observables (testlet)\n\nConsistent with Stout’s (1987) ‘essential n-dimensionality’\nWang, Bradlow & Wainer (2001) SCORIGHT program for IRT\nPatz & Junker (1999) model for multiple ratings\n\n\n\n\n“Context” effect – example\nSuppose that Items 3 and 4 share common presentation material\nExample: a word problem about “Yacht racing” might use nautical jargon like “leeward” and “tacking”\nPeople familiar with the content area would have an advantage over people unfamiliar with the content area.\nWould never us this example in practice because of DIF (Differential Item Functioning)\n\n\nAdding a context variable\nGroup Items 3 and 4 into a single task with two observed outcome variables\nAdd a person-specific, task-specific latent variable called “context” with values familiar and unfamiliar\nEstimates of  will “integrate out” the context effect\nCan use as a mathematical trick to force dependencies between observables.\n\n\nIRT Model with Context Variable\n\n\n\nProblem Set 2\n\nCompare the following quantities in the context and no context models:\n\nP(X2), P(X3), P(X4)\nP(|X2= right ), P(|X3= right )\nP(X4|X2= right ), P(X4 |X3= right )\nP(|X3= wrong , X4= wrong ), P(|X3= right , X4= wrong ),\nP(|X3= wrong , X4= right ), P(|X3= right , X4= right )\n\n\n\n\nContext Effect Postscript\nIf Context effect is generally construct-irrelevant variance, if correlated with group membership this is bad (DIF)\nWhen calibrating using 2PL IRT model, can get similar joint distribution for  , X 3 , and X 4  by decreasing the discrimination parameter\n\n\n3. Combination Models\nConsider a task which requires two Proficiencies:\nThree different ways to combine those proficiencies:\nCompensatory : More of Proficiency 1 compensates for less of Proficiency 2. Combination rule is sum .\nConjunctive : Both proficiencies are needed to solve the problem. Combination rule is minimum.\nDisjunctive : Two proficiencies represent alternative solution paths to the problem. Combination rule is maximum.\n\n\nCombination Model Graphs\n\n\n\nCommon Setup for All Three Models\nThere are two parent nodes, and both parents are conditionally independent of each other. The difference among the three models lies in the third term below:\n_ P_ ( P 1 , P 2 , X ) = P ( P 1  ) • P ( P 2  ) • P ( X _ _ | P 1 , P 2 )\nThe priors for the parent nodes are the same for the three models with 0.3333 of probability at each of the H, M, and L states.\nThe initial marginal probability for X is the same for the three models (50/50).\n\n\nConditional Probability Tables\nThis table contains the conditional probabilities for the parent nodes (P1 and P2) and the combination model for the three models.\nTable 3 – Part 2\nConditional Problems for Compensatory, Conjunctive, and Disjunctive\nP1 _ P2_ Compensatory Conjunctive Disjunctive “Right” “Right” “Right”\nH H 0.9 0.9 0.7\nH M 0.7 0.7 0.7\nH L 0.5 0.3 0.7\nM H 0.7 0.7 0.7\nM M 0.5 0.7 0.3\nM L 0.3 0.3 0.3\nL H 0.5 0.3 0.7\nL M 0.3 0.3 0.3\nL L 0.1 0.3 0.1\n\n\nProblem Set 3\nVerify that P(P 1 ), P(P 2 ), and P(Obs) are the same for all three models. ( Obs represents either the node Compensatory , Conjunctive, or Disjunctive )\nAssume   Obs  =  right  , Calculate   P(P   1   )   and   P(P   2   )   for all three models. \nAssume   Obs  =  wrong  , Calculate   P(P   1   )   and   P(P   2   )   for all three models.\nAssume   Obs  =  right  , and   P   1   _ = _   H  . Calculate   P(P   2   )   for all three models. \nAssume   Obs  =  right  , and   P   1   _ = _   M  . Calculate   P(P   2   )   for all three models.\nAssume   Obs  =  right  , and   P   1   _ = _   L  . Calculate   P(P   2   )   for all three models.\nExplain the differences\n\n\nActivity 3\n\nGo back to the Driver’s License Exam you built in Session I and add some numbers\nNow put in some observed outcomes\n\nHow did the probabilities change?\nIs that about what you expected?\n\n\n\n\nACED Background\n\nACED (Adaptive Content with Evidence-based Diagnosis)\nVal Shute (PD), Aurora Graf, Jody Underwood, Eric Hansen, Peggy Redman, Russell Almond, Larry Casey, Waverly Hester, Steve Landau, Diego Zapata\nDomain: Middle School Math, Sequences\nProject Goals:\n\nAdaptive Task Selection\nDiagnostic Feedback\nAccessibility\n\n\n\n\nACED Features\n Valid Assessment  .  Based on evidence-centered design (ECD).\n Adaptive Sequencing  .  Tasks presented in line with an adaptive algorithm.\n Diagnostic Feedback  .  Feedback is immediate and addresses common errors and misconceptions.\n Aligned  .  Assessments aligned with (a) state and national standards and (b) curricula in current textbooks.\n\n\nACED Proficiency Model\n\n\n\nTypical Task\n\n\n\nACED Design/Build Process\nIdentify Proficiency variables\nStructure Proficiency Model\nElicit Proficiency Model Parameters\nConstruct Tasks to target proficiencies at Low/Medium/High difficulty\nBuild Evidence Models based on difficulty/Q-Matrix\n\n\nParameterization of Network\n\nProficiency Model:\n\nBased on Regression model of child given parent\nSME provided correlation and intercept\nSME has low confidence in numeric values\n\nEvidence Model Fragment\n\nTasks Scored Right / Wrong\nBased on IRT model\nHigh / Medium / Low corresponds to  = +1/0/-1\nEasy/Medium/Hard corresponds to difficulty -1/0/+1\nDiscrimination of 1\nUsed Q-Matrix to determine which node is parent\n\n\n\n\nPM-EM Algorithm for Scoring\n\nMaster Bayes net with just proficiency model(PM)\nDatabase of Bayes net fragments corresponding to evidence models (EMs), indexed by task ID\nTo score a task:\n\nFind EM fragment corresponding to task\nJoin EM fragment to PM\nEnter Evidence\nAbsorb evidence from EM fragment into network\nDetach EM fragment\n\n\n\n\nAn Example\n\nFive proficiency variables\nThree tasks, with observables {X11}, {X21, X22 , X23}, {X31}.\n\n\nQ: Which observables depend on which proficiency variables?\u000bA: See the Q-matrix (Fischer, Tatsuoka).\n\n\n\n\nq1\nq2\nq3\nq4\nq5\nX23\n\n\n\n\nX11\n1\n0\n0\n0\n0\n–\n\n\nX21\n0\n1\n0\n0\n0\n1\n\n\nX22\n0\n1\n0\n1\n0\n1\n\n\nX23\n0\n0\n0\n0\n0\nN/A\n\n\nX31\n0\n1\n1\n1\n0\n–\n\n\n\n\n\nProficiency Model / Evidence Model Split\n\nFull Bayes net for proficiency model and observables for all tasks can be decomposed into fragments.\n\nProficiency model fragment(s) (PMFs) contain proficiency variables.\nAn evidence model fragment (EMF) for each task.\nEMF contains observables for that task and all proficiency variables that are parents of any of them.\n\nPresumes observables are conditionally independent between tasks, but can be dependent within tasks.\nAllows for adaptively selecting tasks, docking EMF to PMF, and updating PMF on the fly.\n\n\n\nOn the way to PMF and EMFs…\n\nProficiency variables\n\nObservables and proficiency variable parents for the tasks\n\n\nMarry parents, drop directions, and triangulate (in PMF, with respect to all tasks)\n\n\n\n\nFootprints of tasks in proficiency model (figure out from rows in Q-matrix)\n\n\n\n\nResult:\n\nEach EMF implies a join tree for Bayes net propagation.\n\nInitial distributions for proficiency variables are uniform.\n\nThe footprint of the PM in the EMF is a clique intersection between that EMF and the PMF.\nCan “dock” EMFs with PMF one-at-a-time, to …\n\nabsorb evidence from values of observables to that task as updated probabilities for proficiency variables, and\npredict responses in new tasks, to evaluate potential evidentiary value of administering it.\n\n\n\n\nDocking evidence model fragments\n\n\nScoring Exercise\n\n\n\n\n\n\n\n\n\nOutcome\nTask Name\nProficiency Variable\nDifficulty\n\n\n\n\nWrong\ntCommonRatio1a.xml\nCommonRatio\nEasy\n\n\nRight\ntCommonRatio2b.xml\nCommonRatio\nMedium\n\n\nWrong\ntCommonRatio3b.xml\nCommonRatio\nHard\n\n\nWrong\ntExplicitGeometric1a.xml\nExplicitGoemetric\nEasy\n\n\nRight\ntExplicitGeometric2a.xml\nExplicitGoemetric\nMedium\n\n\nWrong\ntExplicitGeometric3b.xml\nExplicitGoemetric\nHard\n\n\nWrong\ntRecursiveRuleGeometric1a.xml\nRecursiveRuleGeometric\nEasy\n\n\nWrong\ntRecursiveRuleGeometric2b.xml\nRecursiveRuleGeometric\nMedium\n\n\nWrong\ntRecursiveRuleGeometric3a.xml\nRecursiveRuleGeometric\nHard\n\n\nRight\ntTableExtendGeometric1a.xml\nTableGeometric\nEasy\n\n\nRight\ntTableExtendGeometric2b.xml\nTableGeometric\nMedium\n\n\nRight\ntTableExtendGeometric3a.xml\nTableGeometric\nHard\n\n\nWrong\ntVerbalRuleExtendModelGeometric1a.xml\nVerbalRuleGeometric\nEasy\n\n\nWrong\ntVerbalRuleExtendModelGeometric1b.xml\nVerbalRuleGeometric\nEasy\n\n\nRight\ntVerbalRuleExtendModelGeometric2a.xml\nVerbalRuleGeometric\nMedium\n\n\nWrong\ntVisualExtendGeometric1a.xml\nVisualGeometric\nEasy\n\n\nWrong\ntVisualExtendGeometric2a.xml\nVisualGeometric\nMedium\n\n\nWrong\ntVisualExtendGeometric3a.xml\nVisualGeometric\nHard\n\n\n\n\n\nWeight of Evidence\nGood (1985)\nH is binary hypothesis, e.g., Proficiency > Medium\nE is evidence for hypothesis\nWeight of Evidence (WOE) is\n\n\n\nProperties of WOE\n“Centibans” (log base 10, multiply by 100)\nPositive for evidence supporting hypothesis, negative for evidence refuting hypothesis\nMovement in tails of distribution as important as movement near center\nBayes theorem using log odds\n\n\nConditional Weight of Evidence\nCan define Conditional Weight of Evidence\nNice Additive properties\nOrder sensitive\nWOE Balance Sheet (Madigan, Mosurski & Almond, 1997)\n\n\n\n\nEvidence Balance Sheet\n63 tasks total\n1 Easy\n2 Medium\n3 Hard\na Item type\nb Isomorph\nP(Solve Geom Sequences)\n\n\n\nTask\nAcc\nH\nM\nL\n\n\n\n\nSolveGeometricProblems2a\n0\n0.16\n0.26\n0.58\n\n\nSolveGeometricProblems3a\n1\n0.35\n0.35\n0.30\n\n\nSolveGeometricProblems3b\n1\n0.64\n0.29\n0.07\n\n\nSolveGeometricProblems2b\n1\n0.83\n0.16\n0.01\n\n\nVisualExtendTable2a\n1\n0.89\n0.10\n0.01\n\n\nSolveGeometricProblems1a\n0\n0.78\n0.21\n0.01\n\n\nSolveGeometricProblems1b\n1\n0.82\n0.18\n0.00\n\n\nVisualExtendVerbalRule2a\n1\n0.85\n0.15\n0.00\n\n\nModelExtendTableGeometric3a\n1\n0.90\n0.10\n0.00\n\n\nExamplesGeometric2a\n0\n0.87\n0.13\n0.00\n\n\nVisualExplicitVerbalRule3a\n1\n0.91\n0.09\n0.00\n\n\nVerbalRuleModelGeometric3a\n1\n0.95\n0.05\n0.00\n\n\n\nWOE for H vs. M, L\n\n\nExpected Weight of Evidence\nWhen choosing next “test” (task/item) look at expected value of WOE where expectation is taken wrt P(E|H) .\nwhere represent the possible results.\n\n\n\n\nCalculating EWOE\nMadigan and Almond (1996)\nEnter any observed evidence into net\nInstantiate Hypothesis = True (may need to use virtual evidence if hypothesis is compound)\nCalculate for each candidate item\nInstantiate Hypothesis = False\nCalculate for each candidate item\n\n\n\n\nRelated Measures\nValue of Information\nS is proficiency state\nd is decision\nu is utility\n\n\n\nRelated Measures (2)\nMutual Information\nExtends to non-binary hypothesis nodes\nKullback-Liebler distance between joint distribution and independence\n\n\n\n\nTask Selection Exercise 1\n\nUse ACEDMotif1.dne\n\nEasy, Medium, and Hard tasks for Common Ratio and Visual Geometric\n\nUse Hypothesis SolveGeometricProblems > Medium\nCalculate EWOE for six observables\nAssume candidate gets first item right and repeat\n\nNext assume candidate gets first item wrong and repeat\nRepeat exercise using hypothesis SolveGeometricProblems > Low\nUse Network ACEDMotif2.dne\nSelect the SolveGeometricProblems node\nRun the program Network>Sensitivity to Findings\nThis will list the Mutual information for all nodes\nSelect the observable with the highest mutual information as the first task\nUse this to process a person who gets every task right\nUse this to process a person who gets every task wrong\n\n\nACED Evaluation\n\nMiddle School Students\nDid not normally study geometric series\nFour conditions:\n\nElaborated Feedback/Adaptive (E/A; n=71)\nSimple Feedback/Adaptive (S/A; n=75)\nElaborated Feedback/Linear (E/L; n=67)\nControl (no instruction; n=55)\n\nStudents given all 61 geometric items\nAlso given pretest/posttest (25 items each)\n\n\n\nACED Scores\n\n\nFor Each Proficiency Variable\n\nMarginal Distribution\nModal Classification\nEAP Score (High=1, Low=-1)\n\n\n\n\nACED Reliability\n\n\n\nProficiency (EAP)\nReliability\n\n\n\n\nSolve Geometric Sequences (SGS)\n0.88\n\n\nFind Common Ratio\n0.90\n\n\nGenerate Examples\n0.92\n\n\nExtend Sequence\n0.86\n\n\nModel Sequence\n0.80\n\n\nUse Table\n0.82\n\n\nUse Pictures\n0.82\n\n\nInduce Rules\n0.78\n\n\nNumber Right\n0.88\n\n\n\nCalculated with Split Halves (ECD design)\nCorrelation of EAP score with posttest is 0.65 (close to reliability of posttest)\nEven with pretest forced into the equation, EAP score accounted for 17% unique variance\nReliability of modal classifications was worse\n\n\nEffect of Adaptivity\n\nFor adaptive conditions, correlation with posttest seems to hit upper limit by 20 items\nStandard Error of Correlations is large\nJump in linear case related to sequence of items\n\n\nEffect of feedback\nE/A showed significant gains\nOthers did not\nLearning and assessment reliability!!!!!\n\n\nAcknowledgements\nSpecial thanks to Val Shute for letting us used ACED data and models in this tutorial.\nACED development and data collection was sponsored by National Science Foundation Grant No. 0313202.\nComplete data available at: http://ecd.ralmond.net/ecdwiki/ACED/ACED"
  },
  {
    "objectID": "ECD.html#evidence-centered-design",
    "href": "ECD.html#evidence-centered-design",
    "title": "ECD Intro",
    "section": "Evidence Centered Design",
    "text": "Evidence Centered Design\n\nEvidence Centered Design (ECD) provides a mechanism for\n\nCapturing and documenting information about the structure and strength of evidentiary relationships.\nCoordinating the work of test developers in authoring tasks and psychometricians in calibrating the measurement model.\nDocumenting the scientific information that provides the foundation for the assessment and its validity."
  },
  {
    "objectID": "ECD.html#the-central-question",
    "href": "ECD.html#the-central-question",
    "title": "ECD Intro",
    "section": "The Central Question",
    "text": "The Central Question\n\nEvidence-centered design centers around the questions:\n\n“What can we observe about an examinee’s performance which will provide evidence that the examinee has or does not have the knowledge, skills and abilities we wish to make claims about?”\n\n\n“How can we structure situations to be able to make those observations?”\n\n\nThis process results in the Conceptual Assessment Framework (CAF)"
  },
  {
    "objectID": "ECD.html#activity-1-drivers-license-exam",
    "href": "ECD.html#activity-1-drivers-license-exam",
    "title": "ECD Intro",
    "section": "Activity 1: Driver’s License Exam",
    "text": "Activity 1: Driver’s License Exam\nRedesign the driver’s licensure exam\nWrite down several claims you would like to make about people who receive a driver’s license\nGroup your claims into several proficiency variables related to the driver’s test\nDo the claims hold for high, medium or low values of those variables?\nUse Netica as a drawing tool and add your variables"
  },
  {
    "objectID": "ECD.html#ecd---bayes-nets",
    "href": "ECD.html#ecd---bayes-nets",
    "title": "ECD Intro",
    "section": "ECD -> Bayes Nets",
    "text": "ECD -> Bayes Nets\nRepresent Qualitative ECD argument with a graph (Domain Modeling) (Session I)\nTurn graphical structure into probability distribution over proficiency variables and observable outcomes (Bayes net; Session I)\nPerform inference (scoring) using that Bayes net (Session II)\nExpress probabilities in terms of unknown parameters – learn parameters (Session III)\nRefine model based on how well it fits data (Session IV)"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This website is the latest iteration of the notes for the long running series of tutorial Bayesian Networks in Eductional Assessment, which has run at the National Committee for Measurement in Education (NCME) since 2002. It complements the book Bayesian Networks in Educational Assessment available from Springer.\nThe original version was developed by Russell Almond, Bob Mislevy, Duanli Yan and David Williamson with assistance from Linda Steinberg and supported by Educational Testing service.\n\n\n\nETS Logo\n\n\nOver the years, others have contributed materials. In particular, Russell Almond (now at Florida State University), Roy Levy (Arizona State University) and Diego Zapata (Educational Testing Service).\n\n\n\nFSU Seal\n\n\nSpecial thanks to Val Shute (ETS and FSU) for letting us used ACED data and models in this tutorial. ACED development and data collection was sponsored by National Science Foundation Grant No. 0313202. Complete data available at: http://ecd.ralmond.net/ecdwiki/ACED/ACED"
  },
  {
    "objectID": "about.html#current-presenters",
    "href": "about.html#current-presenters",
    "title": "About",
    "section": "Current Presenters",
    "text": "Current Presenters\n Russell Almond is an Associate Professor of Measurement and Statistics at Florida State University. He has long been interested in the intersection of artificial intelligence and statistics. With Bob Mislevy and Linda Steinberg he developed the initial version of evidence-centered assessment design (ECD). His home page is at https://ralmond.net, and he adminsters the machine https://pluto.coe.fsu.edu. His R packages are available through https://ralmond.r-universe.net and the source code is at https://github.com/ralmond, and his Mastadon handle is @ralmond@mlhangout.\n\n\n\nDuanli Yan\n\n\n\n\n\nDiego Zapata"
  },
  {
    "objectID": "about.html#acknowledgements",
    "href": "about.html#acknowledgements",
    "title": "About",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nWe have a lot of people to thank in the making of this tutorial. Obviously Bob and David played big roles in the development of the original tutorials (and we are still using some of their slides). They also helped with the planning for this 2nd edition. Linda Steinberg was extremely important in the original development of both evidence-centered assessment design and many of the original applications using Bayesian networks, particularly Biomass. Here project management skills drove us to find practical problems for many issues. Val Shute has generously offered us the Bayesian networks and data from here ACED project to use as examples. Brent Boerlage @ Norsys has generously provided us with time-limited keys for Netica (although many of the class exercises can be done with the student version). More information about both the Netica GUI and API (needed for RNetica to work) can be found at http://norsys.com/. ETS has generously covered the cost of printing and shipping the paper copies of the slides and Springer has been helpful in arranging for copies of the book Bayesian Networks in Educational Assessment to be available at the tutorial. Last but not least, we would like to thank the NCME staff and volunteers for arranging a host of important details without which this would be a much less pleasant version.\nFinally, we want to thank all of you who have come to the tutorial over the past decade. Your questions and feedback have helped us mold the tutorial to better meet the needs of the NCME audience. We hope that you will continue to provide us with questions and feedback."
  },
  {
    "objectID": "about.html#support",
    "href": "about.html#support",
    "title": "About",
    "section": "Support",
    "text": "Support\nDevelopment of the original tutorial was supported by the ETS Research Allocation.\nDevelopment of the Peanut suite of tools has been supported in part by\n\nBill & Melinda Gates Foundation grant “Games as Learning/Assessment: Stealth Assessment” (#0PP1035331, Val Shute, PI)\nNational Science Foundation grant “DIP: Game-based Assessment and Support of STEM-related Competencies” (#1628937, Val Shute, PI)\nNational Scient Foundation grant “Mathematical Learning via Architectual Design and Modeling Using E-Rebuild.” (#1720533, Fengfeng Ke & Russell Almond, PIs)\nInstitute of Educational Statistics Grant: “Exploring adaptive cognitive and affective learning support for next-generation STEM learning games.” (#R305A170376-20, Val Shute and Russell Almond, PIs"
  },
  {
    "objectID": "about.html#legal-stuff",
    "href": "about.html#legal-stuff",
    "title": "About",
    "section": "Legal Stuff",
    "text": "Legal Stuff\nSlides and handouts for the original tutorial are copyright 2002—2015 Educational Testing Service. Sessions I and II are copyright 2017-8 Educational Testing Service. Session III is copyright 2017-8 Russell G. Almond and includes material from the 2002—2015 used by permission of ETS. Session IV is copyright 2017-8 Roy Levy.\nThese materials are an unpublished, proprietary works of their respective rights holders. Any limited distribution shall not constitute publication. This work may not be reproduced or distributed to third parties without prior written consent. Submit request for the ETS material (Sessions I and II) through http://www.ets.org/legal/copyright.html, and for Sessions III to Russell Almond (ralmond@fsu.edu) and Session IV to Roy Levy (roy.levy@asu.edu)."
  },
  {
    "objectID": "BayesNets.html#irt-taskevidence-model",
    "href": "BayesNets.html#irt-taskevidence-model",
    "title": "Bayesian Networks",
    "section": "IRT Task/Evidence Model",
    "text": "IRT Task/Evidence Model\nTasks yield an work product which can be unambiguously scored right or wrong.\nEach task has a single observable outcome variable.\nTasks are often called items, although the common usage often blurs the distinction between the presentation of the item and the outcome variable."
  },
  {
    "objectID": "BayesNets.html#irt-rasch-evidence-model",
    "href": "BayesNets.html#irt-rasch-evidence-model",
    "title": "Bayesian Networks",
    "section": "IRT (Rasch) Evidence Model",
    "text": "IRT (Rasch) Evidence Model\n\nLet \\(X_j\\) be observable outcome variable from Task \\(j\\).\n\\(\\Pr(X_j =\\text{right} | \\theta, \\beta_j) = \\frac{1}{1+e^{-(\\theta-\\beta_j)}}\\) - \\(\\beta_j\\) is the difficulty of the item.\nCan crank through the formula for each of the five possible values of \\(\\theta\\) to get values for Conditional Probability Tables (CPT)"
  },
  {
    "objectID": "BayesNets.html#irt-assembly-model",
    "href": "BayesNets.html#irt-assembly-model",
    "title": "Bayesian Networks",
    "section": "IRT Assembly Model",
    "text": "IRT Assembly Model\n5 items\nIncreasing difficulty:\n\\[ (\\beta_1, \\ldots, \\beta_5) = (-1.5, -0.75, 0, 0.75, 1.5)\\ \\] .\n\nirt1pl <- function(theta,beta) {\n  1/(1+exp(beta-theta))\n}\nirt1pl(c(-2,-1,0,1,2),0)\n\n[1] 0.1192029 0.2689414 0.5000000 0.7310586 0.8807971\n\n\nItems are presented adaptively."
  },
  {
    "objectID": "BayesNets.html#conditional-probability-tables",
    "href": "BayesNets.html#conditional-probability-tables",
    "title": "Bayesian Networks",
    "section": "Conditional Probability Tables",
    "text": "Conditional Probability Tables\n\n\n\nθ\nPrior\nItem 1\nItem 2\nItem 3\nItem 4\nItem 5\n\n\n\n\n-2\n0.1\n0.3775\n0.2227\n0.1192\n0.0601\n0.0293\n\n\n-1\n0.2\n0.6225\n0.4378\n0.2689\n0.1480\n0.0759\n\n\n0\n0.4\n0.8176\n0.6792\n0.5000\n0.3208\n0.1824\n\n\n1\n0.2\n0.9241\n0.8520\n0.7311\n0.5622\n0.3775\n\n\n2\n0.1\n0.9707\n0.9399\n0.8088\n0.7773\n0.6225"
  },
  {
    "objectID": "BayesNets.html#problems-set-1",
    "href": "BayesNets.html#problems-set-1",
    "title": "Bayesian Networks",
    "section": "Problems Set 1",
    "text": "Problems Set 1\nUse the network CompensatoryConjunctiveNets/IRT5.dne to answer these questions.\n\n#|include: FALSE\n#system(\"netica CompensatoryConjunctiveNets/IRT5.dne\")\n\nInside Netica, to set a node to a value either, click on the value name, or right click and select the value.\nTo clear a value, click on it again, or right click and select “undefined”.\n\nAssume \\(\\theta =1\\), what is expected score (sum \\(X_j\\) )\nCalculate \\(P(\\theta |X_1 \\text{right})\\), \\(E[\\theta |X_1 =\\text{right}]\\).\nCalculate \\(P(\\theta |X_5 = \\text{right})\\), \\(E[\\theta |X_5 = \\text{right}]\\).\nScore three students who have the following observable patterns (Tasks 1--5):\n\n\n1,1,1,0,0\n1,0,0,1,1\n1,1,1,0,1\n\n\nSuppose we have observed for a given student \\(X_2 = \\text{right}\\) and \\(X_3=\\text{right}\\) , what is the next best item to present (hint, look for expected probabilities closest to .5,.5\nSame thing, with \\(X_2 = \\text{right}\\) and \\(X_3=\\text{wrong}\\)\nSame thing, with \\(X_2 = \\text{wrong}\\) and \\(X_3=\\text{wrong}\\)"
  },
  {
    "objectID": "BayesNets.html#context-effect-variables",
    "href": "BayesNets.html#context-effect-variables",
    "title": "Bayesian Networks",
    "section": "“Context” effect – Variables",
    "text": "“Context” effect – Variables\n\nDiagrammeR::grViz('\ndigraph IRTC {\n  subgraph{ Q[label=\"θ\"]; Context }\n  subgraph {\n  X1; X2; X3; X4; X5;\n  }\n  Q -> X1; Q-> X2; Q-> X3; Q->X4; Q->X5\n  Context -> X3; Context -> X4;\n}')\n\n\n\n\n\n\nContext variable – A parent variable introduced to handle conditional dependence among observables (testlet)\n\nConsistent with Stout’s (1987) ‘essential n-dimensionality’\nWang, Bradlow & Wainer (2001) SCORIGHT program for IRT\nPatz & Junker (1999) model for multiple ratings"
  },
  {
    "objectID": "BayesNets.html#context-effect-example",
    "href": "BayesNets.html#context-effect-example",
    "title": "Bayesian Networks",
    "section": "“Context” effect – example",
    "text": "“Context” effect – example\nSuppose that Items 3 and 4 share common presentation material\nExample: a word problem about “Yacht racing” might use nautical jargon like “leeward” and “tacking”\nPeople familiar with the content area would have an advantage over people unfamiliar with the content area.\nWould never us this example in practice because of DIF (Differential Item Functioning)"
  },
  {
    "objectID": "BayesNets.html#adding-a-context-variable",
    "href": "BayesNets.html#adding-a-context-variable",
    "title": "Bayesian Networks",
    "section": "Adding a context variable",
    "text": "Adding a context variable\nGroup Items 3 and 4 into a single task with two observed outcome variables\nAdd a person-specific, task-specific latent variable called “context” with values familiar and unfamiliar\nEstimates of \\(\\theta\\) will “integrate out” the context effect\nCan use as a mathematical trick to force dependencies between observables."
  },
  {
    "objectID": "BayesNets.html#irt-model-with-context-variable",
    "href": "BayesNets.html#irt-model-with-context-variable",
    "title": "Bayesian Networks",
    "section": "IRT Model with Context Variable",
    "text": "IRT Model with Context Variable\nUse the network CompensatoryConjunctiveNets/IRT5C.dne to answer these questions.\n\n#|include: FALSE\n#system(\"netica CompensatoryConjunctiveNets/IRT5C.dne\")\n\nThe CPTs in IRT5C have been set so that the marginal predictions (if the context is unknown), should have the same value.\n\n\n\nIRT model with Context Effect"
  },
  {
    "objectID": "BayesNets.html#problem-set-2",
    "href": "BayesNets.html#problem-set-2",
    "title": "Bayesian Networks",
    "section": "Problem Set 2",
    "text": "Problem Set 2\n\nCompare the following quantities in the context and no context models:\n\n\\(P(X_2)\\), \\(P(X_3)\\), \\(P(X_4)\\)\n\\(P(\\theta|X_2= \\text{right})\\), \\(P(\\theta|X_3= \\text{right} )\\)\n\\(P(X_4|X_2= \\text{right} )\\), \\(P(X_4 |X_3= \\text{right} )\\)\n\\(P(\\theta|X_3=\\text{wrong}, X_4=\\text{wrong})\\), \\(P(\\theta|X_3=\\text{right}, X_4=\\text{wrong})\\),\n\\(P(\\theta|X_3=\\text{wrong}, X_4=\\text{right})\\), \\(P(\\theta|X_3= \\text{right}, X_4=\\text{right})\\)"
  },
  {
    "objectID": "BayesNets.html#context-effect-postscript",
    "href": "BayesNets.html#context-effect-postscript",
    "title": "Bayesian Networks",
    "section": "Context Effect Postscript",
    "text": "Context Effect Postscript\nIf Context effect is generally construct-irrelevant variance, if correlated with group membership this is bad (DIF)\nWhen calibrating using 2PL IRT model, can get similar joint distribution for \\(\\theta\\), \\(X_3\\), and \\(X_4\\) by decreasing the discrimination parameter"
  },
  {
    "objectID": "BayesNets.html#common-setup-for-all-three-models",
    "href": "BayesNets.html#common-setup-for-all-three-models",
    "title": "Bayesian Networks",
    "section": "Common Setup for All Three Models",
    "text": "Common Setup for All Three Models\nThere are two parent nodes, and both parents are conditionally independent of each other. The difference among the three models lies in the third term below:\n\\[P( P_1, P_2, X) = P( P_1) \\cdot P(P_2) \\cdot P(X| P_1,P_2 )\\]\nThe priors for the parent nodes are the same for the three models with 0.3333 of probability at each of the H, M, and L states.\nThe initial marginal probability for X is the same for the three models (50/50)."
  },
  {
    "objectID": "BayesNets.html#conditional-probability-tables-1",
    "href": "BayesNets.html#conditional-probability-tables-1",
    "title": "Bayesian Networks",
    "section": "Conditional Probability Tables",
    "text": "Conditional Probability Tables\nThis table contains the conditional probabilities for the parent nodes (P1 and P2) and the combination model for the three models.\n{r CPTcombine3 Pcomp <- c(H=.9,M=.5,L=.1) Pconj <- c(H=.9,M=.7,L=.3) Pdisj <- c(H=.7,M=.3,L=.1) cpts <- data.frame(P1=rep(names(Pcomp),each=3),P2=rep(names(Pcomp),3),                    Compensatory=as.vector(outer(Pcomp,Pcomp,\"+\")/2),                    Conjunctive=as.vector(outer(Pconj,Pconj,\"min\")),                    Disjunctive=as.vector(outer(Pdisj,Pdisj,\"max\"))) knitr::kable(cpts)"
  },
  {
    "objectID": "BayesNets.html#problem-set-3",
    "href": "BayesNets.html#problem-set-3",
    "title": "Bayesian Networks",
    "section": "Problem Set 3",
    "text": "Problem Set 3\nUse the network CompensatoryConjunctiveNets/Comb3Same_1.dne to answer these questions.\n\n#|include: FALSE\n#system(\"netica CompensatoryConjunctiveNets/Comb3Same_1.dne\")\n\n\nVerify that \\(P(P_1)\\), \\(P(P_2)\\) and \\(P(Obs)\\) are the same for all three models. ( Obs represents either the node Compensatory , Conjunctive, or Disjunctive )\nAssume Obs=right; calculate \\(P(P_1)\\) and \\(P(P_2)\\) for all three models.\nAssume Obs=wrong; calculate \\(P(P_1)\\) and \\(P(P_2)\\) for all three models.\nAssume Obs=right, and \\(P_1\\)=H; Calculate \\(P(P_2)\\) for all three models.\nAssume Obs=right, and \\(P_1\\)=M; Calculate \\(P(P_2)\\) for all three models.\nAssume Obs=right, and \\(P_1\\)=L; Calculate \\(P(P_2)\\) for all three models.\n\nExplain the differences"
  },
  {
    "objectID": "BayesNets.html#dibello-models-a-look-ahead",
    "href": "BayesNets.html#dibello-models-a-look-ahead",
    "title": "Bayesian Networks",
    "section": "DiBello Models: A look ahead",
    "text": "DiBello Models: A look ahead\nMap states of parents to points on IRT \\(\\theta\\) scale.\nUse Compensatory (average), Conjunctive (minimum) or Disjunctive (maximum) to combine effective thetas.\nUse IRT (logistic) model to map to probabilities."
  },
  {
    "objectID": "BayesNets.html#activity-3",
    "href": "BayesNets.html#activity-3",
    "title": "Bayesian Networks",
    "section": "Activity 3",
    "text": "Activity 3\n\nGo back to the Driver’s License Exam you built in Session I and add some numbers\nNow put in some observed outcomes\n\nHow did the probabilities change?\nIs that about what you expected?"
  },
  {
    "objectID": "BayesNets.html#aced-background",
    "href": "BayesNets.html#aced-background",
    "title": "Bayesian Networks",
    "section": "ACED Background",
    "text": "ACED Background\n\nACED (Adaptive Content with Evidence-based Diagnosis)\nVal Shute (PD), Aurora Graf, Jody Underwood, Eric Hansen, Peggy Redman, Russell Almond, Larry Casey, Waverly Hester, Steve Landau, Diego Zapata\nDomain: Middle School Math, Sequences\nProject Goals:\n\nAdaptive Task Selection\nDiagnostic Feedback\nAccessibility"
  },
  {
    "objectID": "BayesNets.html#aced-features",
    "href": "BayesNets.html#aced-features",
    "title": "Bayesian Networks",
    "section": "ACED Features",
    "text": "ACED Features\nValid Assessment . Based on evidence-centered design (ECD).\nAdaptive Sequencing . Tasks presented in line with an adaptive algorithm.\nDiagnostic Feedback . Feedback is immediate and addresses common errors and misconceptions.\nAligned . Assessments aligned with (a) state and national standards and (b) curricula in current textbooks."
  },
  {
    "objectID": "BayesNets.html#pm-em-algorithm-for-scoring",
    "href": "BayesNets.html#pm-em-algorithm-for-scoring",
    "title": "Bayesian Networks",
    "section": "PM-EM Algorithm for Scoring",
    "text": "PM-EM Algorithm for Scoring\n\nMaster Bayes net with just proficiency model(PM)\nDatabase of Bayes net fragments corresponding to evidence models (EMs), indexed by task ID\nTo score a task:\n\nFind EM fragment corresponding to task\nJoin EM fragment to PM\nEnter Evidence\nAbsorb evidence from EM fragment into network\nDetach EM fragment"
  },
  {
    "objectID": "BayesNets.html#an-example",
    "href": "BayesNets.html#an-example",
    "title": "Bayesian Networks",
    "section": "An Example",
    "text": "An Example\n\nFive proficiency variables\nThree tasks, with observables {X11}, {X21, X22 , X23}, {X31}."
  },
  {
    "objectID": "BayesNets.html#q-which-observables-depend-on-which-proficiency-variables",
    "href": "BayesNets.html#q-which-observables-depend-on-which-proficiency-variables",
    "title": "Bayesian Networks",
    "section": "Q: Which observables depend on which proficiency variables?",
    "text": "Q: Which observables depend on which proficiency variables?\nA: See the Q-matrix (Fischer, Tatsuoka).\n\n\n\n\nq1\nq2\nq3\nq4\nq5\nX23\n\n\n\n\nX11\n1\n0\n0\n0\n0\n–\n\n\nX21\n0\n1\n0\n0\n0\n1\n\n\nX22\n0\n1\n0\n1\n0\n1\n\n\nX23\n0\n0\n0\n0\n0\nN/A\n\n\nX31\n0\n1\n1\n1\n0\n–"
  },
  {
    "objectID": "BayesNets.html#proficiency-model-evidence-model-split",
    "href": "BayesNets.html#proficiency-model-evidence-model-split",
    "title": "Bayesian Networks",
    "section": "Proficiency Model / Evidence Model Split",
    "text": "Proficiency Model / Evidence Model Split\n\nFull Bayes net for proficiency model and observables for all tasks can be decomposed into fragments.\n\nProficiency model fragment(s) (PMFs) contain proficiency variables.\nAn evidence model fragment (EMF) for each task.\nEMF contains observables for that task and all proficiency variables that are parents of any of them.\n\nPresumes observables are conditionally independent between tasks, but can be dependent within tasks.\nAllows for adaptively selecting tasks, docking EMF to PMF, and updating PMF on the fly."
  },
  {
    "objectID": "BayesNets.html#on-the-way-to-pmf-and-emfs",
    "href": "BayesNets.html#on-the-way-to-pmf-and-emfs",
    "title": "Bayesian Networks",
    "section": "On the way to PMF and EMFs…",
    "text": "On the way to PMF and EMFs…\n\nProficiency variables\n\nObservables and proficiency variable parents for the tasks"
  },
  {
    "objectID": "BayesNets.html#marry-parents-drop-directions-and-triangulate-in-pmf-with-respect-to-all-tasks",
    "href": "BayesNets.html#marry-parents-drop-directions-and-triangulate-in-pmf-with-respect-to-all-tasks",
    "title": "Bayesian Networks",
    "section": "Marry parents, drop directions, and triangulate (in PMF, with respect to all tasks)",
    "text": "Marry parents, drop directions, and triangulate (in PMF, with respect to all tasks)\n\n\n$# Footprints of tasks in proficiency model (figure out from rows in Q-matrix)"
  },
  {
    "objectID": "BayesNets.html#result",
    "href": "BayesNets.html#result",
    "title": "Bayesian Networks",
    "section": "Result:",
    "text": "Result:\n\nEach EMF implies a join tree for Bayes net propagation.\n\nInitial distributions for proficiency variables are uniform.\n\nThe footprint of the PM in the EMF is a clique intersection between that EMF and the PMF.\nCan “dock” EMFs with PMF one-at-a-time, to …\n\nabsorb evidence from values of observables to that task as updated probabilities for proficiency variables, and\npredict responses in new tasks, to evaluate potential evidentiary value of administering it."
  },
  {
    "objectID": "BayesNets.html#docking-evidence-model-fragments",
    "href": "BayesNets.html#docking-evidence-model-fragments",
    "title": "Bayesian Networks",
    "section": "Docking evidence model fragments",
    "text": "Docking evidence model fragments"
  },
  {
    "objectID": "BayesNets.html#properties-of-woe",
    "href": "BayesNets.html#properties-of-woe",
    "title": "Bayesian Networks",
    "section": "Properties of WOE",
    "text": "Properties of WOE\n“Centibans” (log base 10, multiply by 100)\nPositive for evidence supporting hypothesis, negative for evidence refuting hypothesis\nMovement in tails of distribution as important as movement near center\nBayes theorem using log odds"
  },
  {
    "objectID": "BayesNets.html#conditional-weight-of-evidence",
    "href": "BayesNets.html#conditional-weight-of-evidence",
    "title": "Bayesian Networks",
    "section": "Conditional Weight of Evidence",
    "text": "Conditional Weight of Evidence\nCan define Conditional Weight of Evidence\nNice Additive properties\nOrder sensitive\nWOE Balance Sheet (Madigan, Mosurski & Almond, 1997)"
  },
  {
    "objectID": "BayesNets.html#evidence-balance-sheet",
    "href": "BayesNets.html#evidence-balance-sheet",
    "title": "Bayesian Networks",
    "section": "Evidence Balance Sheet",
    "text": "Evidence Balance Sheet\n63 tasks total\n1 Easy\n2 Medium\n3 Hard\na Item type\nb Isomorph\nP(Solve Geom Sequences)\n\n\n\nTask\nAcc\nH\nM\nL\n\n\n\n\nSolveGeometricProblems2a\n0\n0.16\n0.26\n0.58\n\n\nSolveGeometricProblems3a\n1\n0.35\n0.35\n0.30\n\n\nSolveGeometricProblems3b\n1\n0.64\n0.29\n0.07\n\n\nSolveGeometricProblems2b\n1\n0.83\n0.16\n0.01\n\n\nVisualExtendTable2a\n1\n0.89\n0.10\n0.01\n\n\nSolveGeometricProblems1a\n0\n0.78\n0.21\n0.01\n\n\nSolveGeometricProblems1b\n1\n0.82\n0.18\n0.00\n\n\nVisualExtendVerbalRule2a\n1\n0.85\n0.15\n0.00\n\n\nModelExtendTableGeometric3a\n1\n0.90\n0.10\n0.00\n\n\nExamplesGeometric2a\n0\n0.87\n0.13\n0.00\n\n\nVisualExplicitVerbalRule3a\n1\n0.91\n0.09\n0.00\n\n\nVerbalRuleModelGeometric3a\n1\n0.95\n0.05\n0.00\n\n\n\nWOE for H vs. M, L"
  },
  {
    "objectID": "BayesNets.html#expected-weight-of-evidence",
    "href": "BayesNets.html#expected-weight-of-evidence",
    "title": "Bayesian Networks",
    "section": "Expected Weight of Evidence",
    "text": "Expected Weight of Evidence\nWhen choosing next “test” (task/item) look at expected value of WOE where expectation is taken wrt P(E|H) .\nwhere represent the possible results."
  },
  {
    "objectID": "BayesNets.html#calculating-ewoe",
    "href": "BayesNets.html#calculating-ewoe",
    "title": "Bayesian Networks",
    "section": "Calculating EWOE",
    "text": "Calculating EWOE\nMadigan and Almond (1996)\nEnter any observed evidence into net\nInstantiate Hypothesis = True (may need to use virtual evidence if hypothesis is compound)\nCalculate for each candidate item\nInstantiate Hypothesis = False\nCalculate for each candidate item\n\n\n$# Related Measures\nValue of Information\nS is proficiency state\nd is decision\nu is utility"
  },
  {
    "objectID": "BayesNets.html#related-measures-2",
    "href": "BayesNets.html#related-measures-2",
    "title": "Bayesian Networks",
    "section": "Related Measures (2)",
    "text": "Related Measures (2)\nMutual Information\nExtends to non-binary hypothesis nodes\nKullback-Liebler distance between joint distribution and independence"
  },
  {
    "objectID": "BayesNets.html#task-selection-exercise-1",
    "href": "BayesNets.html#task-selection-exercise-1",
    "title": "Bayesian Networks",
    "section": "Task Selection Exercise 1",
    "text": "Task Selection Exercise 1\n\nUse ACEDMotif1.dne\n\nEasy, Medium, and Hard tasks for Common Ratio and Visual Geometric\n\nUse Hypothesis SolveGeometricProblems > Medium\nCalculate EWOE for six observables\nAssume candidate gets first item right and repeat\n\nNext assume candidate gets first item wrong and repeat\nRepeat exercise using hypothesis SolveGeometricProblems > Low\nUse Network ACEDMotif2.dne\nSelect the SolveGeometricProblems node\nRun the program Network>Sensitivity to Findings\nThis will list the Mutual information for all nodes\nSelect the observable with the highest mutual information as the first task\nUse this to process a person who gets every task right\nUse this to process a person who gets every task wrong"
  },
  {
    "objectID": "BayesNets.html#aced-evaluation",
    "href": "BayesNets.html#aced-evaluation",
    "title": "Bayesian Networks",
    "section": "ACED Evaluation",
    "text": "ACED Evaluation\n\nMiddle School Students\nDid not normally study geometric series\nFour conditions:\n\nElaborated Feedback/Adaptive (E/A; n=71)\nSimple Feedback/Adaptive (S/A; n=75)\nElaborated Feedback/Linear (E/L; n=67)\nControl (no instruction; n=55)\n\nStudents given all 61 geometric items\nAlso given pretest/posttest (25 items each)"
  },
  {
    "objectID": "BayesNets.html#aced-scores",
    "href": "BayesNets.html#aced-scores",
    "title": "Bayesian Networks",
    "section": "ACED Scores",
    "text": "ACED Scores\n\n\n\nACED Marginal Distributions\n\n\n\nFor Each Proficiency Variable\n\nMarginal Distribution\nModal Classification\nEAP Score (High=1, Low=-1)"
  },
  {
    "objectID": "BayesNets.html#aced-reliability",
    "href": "BayesNets.html#aced-reliability",
    "title": "Bayesian Networks",
    "section": "ACED Reliability",
    "text": "ACED Reliability\n\n\n\nProficiency (EAP)\nReliability\n\n\n\n\nSolve Geometric Sequences (SGS)\n0.88\n\n\nFind Common Ratio\n0.90\n\n\nGenerate Examples\n0.92\n\n\nExtend Sequence\n0.86\n\n\nModel Sequence\n0.80\n\n\nUse Table\n0.82\n\n\nUse Pictures\n0.82\n\n\nInduce Rules\n0.78\n\n\nNumber Right\n0.88\n\n\n\nCalculated with Split Halves (ECD design)\nCorrelation of EAP score with posttest is 0.65 (close to reliability of posttest)\nEven with pretest forced into the equation, EAP score accounted for 17% unique variance\nReliability of modal classifications was worse"
  },
  {
    "objectID": "BayesNets.html#effect-of-adaptivity",
    "href": "BayesNets.html#effect-of-adaptivity",
    "title": "Bayesian Networks",
    "section": "Effect of Adaptivity",
    "text": "Effect of Adaptivity\n\n\n\nACED Validity by test length\n\n\nFor adaptive conditions, correlation with posttest seems to hit upper limit by 20 items\nStandard Error of Correlations is large\nJump in linear case related to sequence of items"
  },
  {
    "objectID": "BayesNets.html#effect-of-feedback",
    "href": "BayesNets.html#effect-of-feedback",
    "title": "Bayesian Networks",
    "section": "Effect of feedback",
    "text": "Effect of feedback\nE/A showed significant gains\nOthers did not\nLearning and assessment reliability!!!!!"
  },
  {
    "objectID": "BayesNets.html#acknowledgements",
    "href": "BayesNets.html#acknowledgements",
    "title": "Bayesian Networks",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nSpecial thanks to Val Shute for letting us used ACED data and models in this tutorial.\nACED development and data collection was sponsored by National Science Foundation Grant No. 0313202.\nComplete data available at: http://ecd.ralmond.net/ecdwiki/ACED/ACED"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "PeanutTutorial",
    "section": "",
    "text": "This website contains the downloads and handouts for the tutorial Bayesian Networks in Educational Assessment. using the Peanut Bayesian network toolkit.\nYou can access this tutorial in two ways:\n\nOnline viewing through https://pluto.coe.fsu.edu/PeanutTutorial.\nDownload the source code from https://github.com/ralmond/PeanutTutorial.git.\n\nThe latter allows you to reproduce the calculations on your own computer using R Studio. See the Resources page for more information about the software you need to download.\nThe complete tutorial has the following parts:\n\nIntroduction to Evidence-Centered Assessment Design and Bayesian Networks\nExample Bayesian Networks\nUsing Peanut to Manipulate Bayes nets\n\n\n\nScoring using RNetica\nBuilding a Net with Peanut\nCalibrating Model Parameters to Data\n\n\n\nDynamic Bayesian Networks"
  }
]